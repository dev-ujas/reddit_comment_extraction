{
    "title": "Stop asking data scientist riddles in interviews!",
    "id": "qrjmge",
    "create_at": 1636631533.0,
    "score": 2324,
    "comments": [
        {
            "id": "hk9i4c0",
            "parent": "t1_hk7x9dr",
            "ans": ">I\u2019ve never seen a candidate not struggle, take forever and feel demoralized afterwards.\n\nWell you made me feel a bit better, at least.",
            "score": 36,
            "que": "I\u2019m not technically a data scientist. I work as a quant in finance and my work overlaps quite a bit. Every interview I\u2019ve been in with coworkers (or job I\u2019ve interviewed for), focused on brain teasers and case studies way too often. Everyone always says that it shows them \u201chow they think,\u201d but it\u2019s total bullshit. I\u2019ve never seen a candidate not struggle, take forever and feel demoralized afterwards. I\u2019m not convinced that the purpose of these questions are anything but dick measuring contests. It\u2019s a waste of time and will tell you almost nothing about the person compared to in depth questions about past experience and projects."
        },
        {
            "id": "hkapaw7",
            "parent": "t1_hk7x9dr",
            "ans": "Google used to ask brain teaser questions, typically Fermi questions like, \"How many balls fit inside of the empire state building?\"\n\nAt first Google thought it showed thought process, the \"how they think\" bit, and maybe it does to some extent, but over years of studying employee performance there has been shown no correlation to riddle and trivia type questions.  These type of questions are now banned from interviews.\n\nStudies show while interviewing giving easy questions lowers the noise threshold for candidate competence, so an ideal technical interview asks easy questions and then compares interviewer to interviewer finding the best candidate.  edit: To be clear, an easy question does not mean a trivia question (some people get tripped up on this).  Eg, \"Explain what a p-value is.\" is an easy question, but also a trivia question.  You don't want to ask trivia questions because it will give an advantage to fresh graduates and give a disadvantage to seniors.",
            "score": 34,
            "que": "I\u2019m not technically a data scientist. I work as a quant in finance and my work overlaps quite a bit. Every interview I\u2019ve been in with coworkers (or job I\u2019ve interviewed for), focused on brain teasers and case studies way too often. Everyone always says that it shows them \u201chow they think,\u201d but it\u2019s total bullshit. I\u2019ve never seen a candidate not struggle, take forever and feel demoralized afterwards. I\u2019m not convinced that the purpose of these questions are anything but dick measuring contests. It\u2019s a waste of time and will tell you almost nothing about the person compared to in depth questions about past experience and projects."
        },
        {
            "id": "hkbetkg",
            "parent": "t1_hk7x9dr",
            "ans": "I used to work as a data scientist, but I was pretty bad at it; I didn\u2019t care much for the experimental side of it and I put little to no effort into growing. I kill the brain teaser interviews though. I am trained as a mathematician and I love to think, so any question where I am supposed to show \u201cmy thinking process\u201d I really enjoy and I end up impressing people. Then they hire me and realize I\u2019m the worst data scientist they ever had \ud83e\udd23.",
            "score": 15,
            "que": "I\u2019m not technically a data scientist. I work as a quant in finance and my work overlaps quite a bit. Every interview I\u2019ve been in with coworkers (or job I\u2019ve interviewed for), focused on brain teasers and case studies way too often. Everyone always says that it shows them \u201chow they think,\u201d but it\u2019s total bullshit. I\u2019ve never seen a candidate not struggle, take forever and feel demoralized afterwards. I\u2019m not convinced that the purpose of these questions are anything but dick measuring contests. It\u2019s a waste of time and will tell you almost nothing about the person compared to in depth questions about past experience and projects."
        },
        {
            "id": "hka6qsw",
            "parent": "t1_hk7x9dr",
            "ans": ">rs (or job I\u2019ve interviewed for), focused on brain teasers and case studies way too often. Everyone always says that it shows them \u201chow they think,\u201d but it\u2019s total bullshit. I\u2019ve never seen a candidate not struggle, take forever and feel demoralized afterwards. I\u2019m not convinced that the purpose of these questions are anything but dick measuring \n\nthat isnt the interview format that's people being shit interviewers... if you ask question A and... can't get there... you ask question B... at some point you should be going back and forth with the candidate on approaches to X problem.... it's about figuring out if someone can work with you to solve problems... not if they know the answer to a specific problem.  \n\n\nThe issue with just in depth questions about experience and projects **alone** (without trying to problem solve 'live' with the candidate) is that stuff can be bullshitted.",
            "score": 7,
            "que": "I\u2019m not technically a data scientist. I work as a quant in finance and my work overlaps quite a bit. Every interview I\u2019ve been in with coworkers (or job I\u2019ve interviewed for), focused on brain teasers and case studies way too often. Everyone always says that it shows them \u201chow they think,\u201d but it\u2019s total bullshit. I\u2019ve never seen a candidate not struggle, take forever and feel demoralized afterwards. I\u2019m not convinced that the purpose of these questions are anything but dick measuring contests. It\u2019s a waste of time and will tell you almost nothing about the person compared to in depth questions about past experience and projects."
        },
        {
            "id": "hk7o5nz",
            "parent": "t1_hk78rw8",
            "ans": "I've had candidates with good looking resumes be unable to tell me the definition of a p-value and 'portfolios' don't really exist for people in my industry.  Some technical evaluation is absolutely necessary.",
            "score": 64,
            "que": "Typically we use portfolio/experience to evaluate technical skills. What we're looking for in an interview is soft skills and ability to navigate corporate culture. \n\nData scientists have to be able to be technically competent while being socially conscious and not being assholes to non-data scientists."
        },
        {
            "id": "hk8o3iq",
            "parent": "t1_hk78rw8",
            "ans": "Someone should study the best predictors for good data scientist if it hasn't been done already. That should be the natural why a data scientist should look at this. Granted there would be problems with data quantity and quality and what to use as measures, etc. but that's kinda what we expect with many situations data scientists encounter. \n\nFWIW, Google studied the usefulness of its brain teasers during interviews: [Google Finally Admits That Its Infamous Brainteasers Were Completely Useless for Hiring](https://www.theatlantic.com/business/archive/2013/06/google-finally-admits-that-its-infamous-brainteasers-were-completely-useless-for-hiring/277053/)",
            "score": 2,
            "que": "Typically we use portfolio/experience to evaluate technical skills. What we're looking for in an interview is soft skills and ability to navigate corporate culture. \n\nData scientists have to be able to be technically competent while being socially conscious and not being assholes to non-data scientists."
        },
        {
            "id": "hk8fn2h",
            "parent": "t1_hk78rw8",
            "ans": "Socially conscious?  Oh, do you mean \u201chave manners?\u201d",
            "score": 2,
            "que": "Typically we use portfolio/experience to evaluate technical skills. What we're looking for in an interview is soft skills and ability to navigate corporate culture. \n\nData scientists have to be able to be technically competent while being socially conscious and not being assholes to non-data scientists."
        },
        {
            "id": "hk733o1",
            "parent": "t1_hk70rru",
            "ans": "LinkedIn is such a crap hole",
            "score": 208,
            "que": "Never seen anything interesting from this woman who gets pushed in my Linkedin feed all the time."
        },
        {
            "id": "hk7t80m",
            "parent": "t1_hk70rru",
            "ans": "at some point, i woke up and there was this huge influx of DS influencers. i don't know how it started or how they're making money, but i'm confused",
            "score": 37,
            "que": "Never seen anything interesting from this woman who gets pushed in my Linkedin feed all the time."
        },
        {
            "id": "hk88uf4",
            "parent": "t1_hk70rru",
            "ans": "[deleted]",
            "score": 15,
            "que": "Never seen anything interesting from this woman who gets pushed in my Linkedin feed all the time."
        },
        {
            "id": "hk8aarh",
            "parent": "t1_hk70rru",
            "ans": "no shit, she must be paying for some type of social media push. i thought i was getting it because a few connections at amazon (not in datascience)",
            "score": 6,
            "que": "Never seen anything interesting from this woman who gets pushed in my Linkedin feed all the time."
        },
        {
            "id": "hk7lgcd",
            "parent": "t1_hk70rru",
            "ans": "This is the funniest comment of this thread \ud83d\ude02",
            "score": 9,
            "que": "Never seen anything interesting from this woman who gets pushed in my Linkedin feed all the time."
        },
        {
            "id": "hk85puq",
            "parent": "t1_hk70rru",
            "ans": "Yeah, I muted her and some other \"influencers\". Fucking stupid.",
            "score": 3,
            "que": "Never seen anything interesting from this woman who gets pushed in my Linkedin feed all the time."
        },
        {
            "id": "hk7p18u",
            "parent": "t1_hk70rru",
            "ans": "Also that amazon chick who pioneered some AI thing at amazon",
            "score": 5,
            "que": "Never seen anything interesting from this woman who gets pushed in my Linkedin feed all the time."
        },
        {
            "id": "hk91vq6",
            "parent": "t1_hk70rru",
            "ans": "A good chunk of her posts seem alright. Nothing too crazy and generally a lot more useful than a lot of the other stuff that pops up on LinkedIn. \n\nI actually know her though so I could be biased.",
            "score": 4,
            "que": "Never seen anything interesting from this woman who gets pushed in my Linkedin feed all the time."
        },
        {
            "id": "hk81c6p",
            "parent": "t1_hk73yuv",
            "ans": "What were some of the actual questions you got asked?",
            "score": 3,
            "que": "i just got done with a whole bunch of ds interviews (twitter, google, fb, shipt) and didn't get a single brain teaser type probability/combinatorics type question."
        },
        {
            "id": "hk86mep",
            "parent": "t1_hk7b6zc",
            "ans": "This is true. However, under pressure, the slow thinking brain, _necessary_ for DS, isn\u2019t on. If you want to test their ability to recall probability under pressure, youre shooting yourself in the foot. \n\nThe fast thinking a DS should do is comfortable communication with stakeholders + management.",
            "score": 36,
            "que": "Data scientists should be *experts* in probability and probability theory.\n\nThat's what data science is *based on*.\n\nDon't make them calculate some BS numbers by hand or whatever, but absolutely test their understanding of probability. There are A LOT of DS's that make A LOT of mistakes and poor models because they didn't have a good understanding of probability, but rather were good enough programmers that read about some cool ML models.\n\nUnderstanding probability is *fundamental* to the position."
        },
        {
            "id": "hk7yjt5",
            "parent": "t1_hk7b6zc",
            "ans": "Unexpected questions about dropping eggs and breaking plates are not going to tell you anything about their knowledge of probability. Especially when given only a few minutes to answer. Ask them to explain a few advanced probability/statistical concepts. I will never understand the logic behind prioritizing childish problems with no practical application over actual knowledge and experience.",
            "score": 20,
            "que": "Data scientists should be *experts* in probability and probability theory.\n\nThat's what data science is *based on*.\n\nDon't make them calculate some BS numbers by hand or whatever, but absolutely test their understanding of probability. There are A LOT of DS's that make A LOT of mistakes and poor models because they didn't have a good understanding of probability, but rather were good enough programmers that read about some cool ML models.\n\nUnderstanding probability is *fundamental* to the position."
        },
        {
            "id": "hk7svtd",
            "parent": "t1_hk7b6zc",
            "ans": "Yea, but it's too hard and requires actual thinking. Doesn't everybody want a job where their brains are half asleep or in a distant happy place most of the time? For what the man pays, it's only fair.",
            "score": 20,
            "que": "Data scientists should be *experts* in probability and probability theory.\n\nThat's what data science is *based on*.\n\nDon't make them calculate some BS numbers by hand or whatever, but absolutely test their understanding of probability. There are A LOT of DS's that make A LOT of mistakes and poor models because they didn't have a good understanding of probability, but rather were good enough programmers that read about some cool ML models.\n\nUnderstanding probability is *fundamental* to the position."
        },
        {
            "id": "hk8c7jg",
            "parent": "t1_hk7b6zc",
            "ans": "I disagree. You should be at the undergrad level of probability for a math and stats major. Anything else isn\u2019t super needed. But you should probs know how to use docker, Hadoop, kubernetes, AWS or GCP, and other Technical skills. Unless you are doing research anything beyond undergrad level (I.e PhD level stuff) is NOT going be necessary to go far in this field. But your technical and coding skills will take you far with your undergrad level understanding",
            "score": 5,
            "que": "Data scientists should be *experts* in probability and probability theory.\n\nThat's what data science is *based on*.\n\nDon't make them calculate some BS numbers by hand or whatever, but absolutely test their understanding of probability. There are A LOT of DS's that make A LOT of mistakes and poor models because they didn't have a good understanding of probability, but rather were good enough programmers that read about some cool ML models.\n\nUnderstanding probability is *fundamental* to the position."
        },
        {
            "id": "hk7ez2g",
            "parent": "t1_hk7b6zc",
            "ans": "[deleted]",
            "score": -28,
            "que": "Data scientists should be *experts* in probability and probability theory.\n\nThat's what data science is *based on*.\n\nDon't make them calculate some BS numbers by hand or whatever, but absolutely test their understanding of probability. There are A LOT of DS's that make A LOT of mistakes and poor models because they didn't have a good understanding of probability, but rather were good enough programmers that read about some cool ML models.\n\nUnderstanding probability is *fundamental* to the position."
        },
        {
            "id": "hkaf4y0",
            "parent": "t1_hk7b6zc",
            "ans": "I am an expert in data mining, machine learning and AI. I know fuck all about probability (sure I did some undergrad & graduate coursework but I can't remember most of it).\n\nI don't really care about probability because none of the methods I use have any solid theoretical basis in statistics. I have never used any of the statistics knowledge from college in my professional life. And if you're using probability as a data scientist outside of clinical trials I'm fairly confident that you're doing things wrong.\n\nIndustry data science and ML research is ~40-50 years ahead of statistics research. The theory simply hasn't been developed yet. None of the actually useful in the real world methods invented in the past ~40 years have a theory that really proves how they work (as is the case with some older better researched methods).\n\nI know there is a sub category of data scientists that took some statistics coursework and proceed to use the same methods (designed as pedagogical tools to teach a concept/as practical tools for clinical trials or social science) in the industry. Without considering the fact that there are methods that achieve far better results with less effort but were never taught in college due to their low pedagogical value & not being the golden standard in applied statistics for clinical trials/social science quantitative studies (which hasn't changed for ~100 years).\n\nI don't need probability (or any statistics coursework for that matter) to use HDBSCAN, xgboost, autonecoders, matrix profiles etc. or even do ML/data mining research. I'd rather people took more of linear algebra, vector calculus and perhaps dabbled in non-linear optimization and complex network theory.\n\nData science is not statistics. Data scientists are concerned with **representations** of phenomenon. Using TF-IDF for example still doesn't have the statistical theory behind it that explains why it works but anyone that has ever done NLP knows that it's pretty damn effective.\n\n100% of feature engineering I do has no theoretical justification. But it works and it improves results and it brings $$$ to the company. With deep learning the feature engineering is learned from the data and a huge can of worms from a theory standpoint. But it outperforms everything else and you're an idiot if you're not using superior methods and your employer is an idiot for hiring you in the first place.\n\nThere is also a question of whether such theory can be developed in the first place. Many have attempted and it really looks like this modern data science thing doesn't fit in statistics at all and never will fit. Kind of like natural science and mathematics split a few centuries ago because the natural world did not fit into the mathematical world anymore.",
            "score": -1,
            "que": "Data scientists should be *experts* in probability and probability theory.\n\nThat's what data science is *based on*.\n\nDon't make them calculate some BS numbers by hand or whatever, but absolutely test their understanding of probability. There are A LOT of DS's that make A LOT of mistakes and poor models because they didn't have a good understanding of probability, but rather were good enough programmers that read about some cool ML models.\n\nUnderstanding probability is *fundamental* to the position."
        },
        {
            "id": "iuo2pei",
            "parent": "t1_hk7b6zc",
            "ans": "Wow, your comment was so cringe that I felt compelled to reply to it a year in the future. \n\nThe vast majority of successful data scientists could not accurately answer some bullshit combinatorial probability question. They are bad, lazy, and ultimately irrelevant questions. The focus should be on business impact, on past projects. How to use data science to get from point A to point B. \n\nOral regurgitation of probability definitions, or even worse making them to calculations on the fly, is just so reprehensible.",
            "score": 1,
            "que": "Data scientists should be *experts* in probability and probability theory.\n\nThat's what data science is *based on*.\n\nDon't make them calculate some BS numbers by hand or whatever, but absolutely test their understanding of probability. There are A LOT of DS's that make A LOT of mistakes and poor models because they didn't have a good understanding of probability, but rather were good enough programmers that read about some cool ML models.\n\nUnderstanding probability is *fundamental* to the position."
        },
        {
            "id": "hk7xpuh",
            "parent": "t1_hk7l81p",
            "ans": "I\u2019d love to know this as well",
            "score": 5,
            "que": "What source of probability questions are good to check out from time to time? I\u2019ve been in my job for 2.5 years, I\u2019d prolly bomb an interview at this point"
        },
        {
            "id": "hka81fh",
            "parent": "t1_hk7l81p",
            "ans": "Actuarial exams",
            "score": 1,
            "que": "What source of probability questions are good to check out from time to time? I\u2019ve been in my job for 2.5 years, I\u2019d prolly bomb an interview at this point"
        },
        {
            "id": "hk75pcm",
            "parent": "t1_hk70186",
            "ans": "Those brain teaser questions are seen before like textbook exercise or something like that. There is a pattern.",
            "score": 29,
            "que": "The point of the riddles isn't (\\*shouldn't be\\*) to see if you can get the right answer. It's to see how you reason through a problem you've never seen before."
        },
        {
            "id": "hk7lxzn",
            "parent": "t1_hk70186",
            "ans": "I mean, you can ask them a relevant question to the work that they are going to be doing. I fail to see how being able to reason through a graduate-level probability brain teaser is indicative of anything other than not having taken a graduate-level probability course. There are ways of testing probability knowledge without resorting to urns or toy Markov Chains.\n\nIt is practically guaranteed that an applicant isn't an expert on the stuff that they will be working on should they be hired. Why can't we ask questions based on that stuff?",
            "score": 11,
            "que": "The point of the riddles isn't (\\*shouldn't be\\*) to see if you can get the right answer. It's to see how you reason through a problem you've never seen before."
        },
        {
            "id": "hk7etk0",
            "parent": "t1_hk70186",
            "ans": "(Some) People aren\u2019t going to understand\u2014they just want the benefits of a data position without the true skills of an authentic data position.\n\nData is literal knowledge work. If you can\u2019t think and reason to inform, you\u2019re not a data practitioner.",
            "score": 15,
            "que": "The point of the riddles isn't (\\*shouldn't be\\*) to see if you can get the right answer. It's to see how you reason through a problem you've never seen before."
        },
        {
            "id": "hk7to9h",
            "parent": "t1_hk70186",
            "ans": "I had an interview loop years ago which started with a legit fair and business-applicable take-home assignment, which they said I passed and that it was excellent.\n\nThe next step was a phone interview.\n\nThem (paraphrased): \"Given a massive data stream that you can't cache, what is the probability of an input datum matching one that you've already seen in the stream?\"\n\nMe: \"Isn't that a network engineering question?\"\n\nInterview ended right after and I was rejected.",
            "score": 6,
            "que": "The point of the riddles isn't (\\*shouldn't be\\*) to see if you can get the right answer. It's to see how you reason through a problem you've never seen before."
        },
        {
            "id": "hk8ig6e",
            "parent": "t1_hk70186",
            "ans": "The only time I've been asked a riddle in a job interview was for a call center job straight out of college. I think they included it because it was the hot new thing. It certainly wasn't relevant.",
            "score": 2,
            "que": "The point of the riddles isn't (\\*shouldn't be\\*) to see if you can get the right answer. It's to see how you reason through a problem you've never seen before."
        },
        {
            "id": "hk7czxm",
            "parent": "t1_hk74jcx",
            "ans": "[deleted]",
            "score": 2,
            "que": "Yes, how dare anyone demand that data scientists understand probability... Never heard of this person, but I guess you should expect this kind of thing from someone hosting \"The Data Scientist Show\"."
        },
        {
            "id": "hk8h3n7",
            "parent": "t1_hk81wwz",
            "ans": "I happen to know that there are 350 Starbucks stores in NYC and I would estimate the ratio of SBUX to MCD locations is probably like 2:1 or 1.5:1, so that puts us at like... ~200 McDonalds.",
            "score": 1,
            "que": "\u201cHow many McDonalds are in NYC?\u201d\n\n\u201cUhh\u201d"
        },
        {
            "id": "hk7yvha",
            "parent": "t1_hk71cth",
            "ans": "[deleted]",
            "score": 2,
            "que": "The work of a Data Scientist is made of probability riddles. I face one on a daily basis almost. They should test on those more in interviews actually!"
        },
        {
            "id": "hk77ama",
            "parent": "t1_hk720j1",
            "ans": "I can't imagine saying this would ever get a favorable response from an interviewer, lol....",
            "score": 22,
            "que": "I don\u2019t remember who it was that said this but I thought it was a great interview response for if you don\u2019t know how to answer a technical question: \u201cI don\u2019t know how to do that off the top of my head but I know how I could google it and could figure it out in a few seconds\u201d"
        },
        {
            "id": "hk7fcbh",
            "parent": "t1_hk720j1",
            "ans": "[deleted]",
            "score": 6,
            "que": "I don\u2019t remember who it was that said this but I thought it was a great interview response for if you don\u2019t know how to answer a technical question: \u201cI don\u2019t know how to do that off the top of my head but I know how I could google it and could figure it out in a few seconds\u201d"
        },
        {
            "id": "hk72hy8",
            "parent": "t1_hk70tw2",
            "ans": "Depends how many feathers and bricks you can buy for 1\u00a3.",
            "score": 38,
            "que": "Which weighs more, a pound of feathers or a pound of bricks?"
        },
        {
            "id": "hk75krf",
            "parent": "t1_hk70tw2",
            "ans": "I'm not sure, but I do know that [steel is heavier than feathers](https://www.youtube.com/watch?v=N3bEh-PEk1g).",
            "score": 5,
            "que": "Which weighs more, a pound of feathers or a pound of bricks?"
        },
        {
            "id": "hk70uid",
            "parent": "t1_hk70tw2",
            "ans": "Not a riddle.",
            "score": -11,
            "que": "Which weighs more, a pound of feathers or a pound of bricks?"
        },
        {
            "id": "hk7ul0w",
            "parent": "t1_hk70tw2",
            "ans": "\"If you have one bucket that holds 5 gallons and another bucket that holds 10 gallons, how many \\*buckets\\* do you have?\"",
            "score": 1,
            "que": "Which weighs more, a pound of feathers or a pound of bricks?"
        },
        {
            "id": "hk7wzam",
            "parent": "t1_hk7bz6d",
            "ans": "Wondering where you can use problem solving is a problem-solving field is the exact wrong thing to do in an interview. What you should've done is take a deep breath, evaluate, honestly, your current knowledge, let your interviewer know what you think what your approach is, try to solve it that way, talk your way through your thinking process, if you feel you're getting stuck, be upfront about it and ask for clues. Best of all, show your cards: this I know, this I don't, this is how my thought process goes. And meantime showing how you would interact with your boss/co-worker on solving it. And best of all, if you can show a single spark of having fun \\*while\\* dealing with a difficult problem in a supposedly high-stress situation, you're golden.\n\nDon't try to cheat and pretend to solve riddle if you already know the answer. Believe me, we can tell. Telling upfront \"I know this one\", you may still get  a request to present your solution, but be judged on clear and short explanation.\n\nOh yea, be prepared for your solution to be challenged with blatantly wrong and confused \"correct answer\" by your future boss. Entertain one \"what an idiot\" thought(or let it be known if you are one) and you're shown the door. Have conviction if you know you're right, argue in a civil manner, best of all turn this process into the search for truth, remember to have fun, be respectful, but honest.\n\nSee, there's no magic here. Observe the interviewer. Will it be any fun to debug a hard one with him/her after hours on Friday because the board needs answer Monday morning and the current result makes no sense, or will you hate every second of it?",
            "score": 5,
            "que": "THIS. Happened to me during a final stage interview process. I just kept wondering when I would use this in the field. We\u2019re not riddle masters, we just know what to do with data and how to leverage it for better decision making. That\u2019s it."
        },
        {
            "id": "hk7jegb",
            "parent": "t1_hk7bz6d",
            "ans": "Right. And you got beaten by a candidate who could do both. Why is that a problem?",
            "score": 2,
            "que": "THIS. Happened to me during a final stage interview process. I just kept wondering when I would use this in the field. We\u2019re not riddle masters, we just know what to do with data and how to leverage it for better decision making. That\u2019s it."
        },
        {
            "id": "hk75gn1",
            "parent": "t1_hk6zns6",
            "ans": "No it's not",
            "score": 5,
            "que": "What if the business problems are probability brain teasers? I imagine that\u2019s the case for much of FANNG work. That\u2019s why they\u2019re FANNG data science problems."
        },
        {
            "id": "hkdjcqd",
            "parent": "t1_hkapaw7",
            "ans": "I will ask what a p-value is in the next interview. Thanks for the idea.",
            "score": 4,
            "que": "Google used to ask brain teaser questions, typically Fermi questions like, \"How many balls fit inside of the empire state building?\"\n\nAt first Google thought it showed thought process, the \"how they think\" bit, and maybe it does to some extent, but over years of studying employee performance there has been shown no correlation to riddle and trivia type questions.  These type of questions are now banned from interviews.\n\nStudies show while interviewing giving easy questions lowers the noise threshold for candidate competence, so an ideal technical interview asks easy questions and then compares interviewer to interviewer finding the best candidate.  edit: To be clear, an easy question does not mean a trivia question (some people get tripped up on this).  Eg, \"Explain what a p-value is.\" is an easy question, but also a trivia question.  You don't want to ask trivia questions because it will give an advantage to fresh graduates and give a disadvantage to seniors."
        },
        {
            "id": "hvh1sfa",
            "parent": "t1_hkbetkg",
            "ans": "I wanted to know how you can prep for the brain teaser questions. is there any way I can practice them?",
            "score": 2,
            "que": "I used to work as a data scientist, but I was pretty bad at it; I didn\u2019t care much for the experimental side of it and I put little to no effort into growing. I kill the brain teaser interviews though. I am trained as a mathematician and I love to think, so any question where I am supposed to show \u201cmy thinking process\u201d I really enjoy and I end up impressing people. Then they hire me and realize I\u2019m the worst data scientist they ever had \ud83e\udd23."
        },
        {
            "id": "hk82w1c",
            "parent": "t1_hk7o5nz",
            "ans": "The problem is people get nervous in interviews and this causes the brain to shut down. It's a well known psychological behavior. You see it in sports, if one thinks too hard about what they're doing under pressure it causes them to underperform.\n\nThey may know what a p-value is but be unable to explain it in the moment.\n\nSome people are also not neuro-typical, they may have autism or ADHD, and this will make them more likely to fail the question under pressure even if they know it.\n\nI had this happen with a variance/bias question recently. I know the difference, I've used this knowledge before numerous times, I can read up on it and understand it immediately if I forget a few things. However in the moment I couldn't give a good answer because I started getting nervous. I have social anxiety and am on the spectrum.\n\nI've been doing this for 8 years so to be honest a question like \"what's a p-value\" is insulting to a degree. Like what I've done for the last decade doesn't matter in the face of a single oral examination. I didn't fake my masters in mathematics, it's verifiable, why would I be unable to understand variance/bias trade-offs or p-values?\n\nReal work is more like a take-home project. People use references in real work and aren't under pressure to give a specific answer within a single hour or two.\n\nTake-home projects still evaluate for technical competency, they are fairer to neuro-atypical people and I'd argue also more useful evaluations than the typical tech screen simply because it is more like real work. I've used them to hire data scientists numerous times and it always worked out, the people that passed are still employed and outside teams that work with them love them.\n\nYou can always ask for a written explanation of what a p-value is or architect a problem so that if they don't know what it is they will fail.",
            "score": 93,
            "que": "I've had candidates with good looking resumes be unable to tell me the definition of a p-value and 'portfolios' don't really exist for people in my industry.  Some technical evaluation is absolutely necessary."
        },
        {
            "id": "hk8bcjn",
            "parent": "t1_hk7o5nz",
            "ans": "I am a Boistatistician with almost 10 years experience - I have led methods papers in propper stats journals mainly on sample size estimation in niche situations.  If you put me on the spot I couldn't give you a rigourous definition of a P-value either. It is a while since I have needed to know.  I could have done when I was straight out of my Masters though, no bother! Am I a better statistican now than I was then? Absolutley.",
            "score": 23,
            "que": "I've had candidates with good looking resumes be unable to tell me the definition of a p-value and 'portfolios' don't really exist for people in my industry.  Some technical evaluation is absolutely necessary."
        },
        {
            "id": "hk89i4r",
            "parent": "t1_hk7o5nz",
            "ans": "Instead if asking about p-values, I tend to ask candidates how they know their model is connected to reality, and how they would explain that to a business client.",
            "score": 6,
            "que": "I've had candidates with good looking resumes be unable to tell me the definition of a p-value and 'portfolios' don't really exist for people in my industry.  Some technical evaluation is absolutely necessary."
        },
        {
            "id": "hk7xsbk",
            "parent": "t1_hk7o5nz",
            "ans": "[deleted]",
            "score": 19,
            "que": "I've had candidates with good looking resumes be unable to tell me the definition of a p-value and 'portfolios' don't really exist for people in my industry.  Some technical evaluation is absolutely necessary."
        },
        {
            "id": "hk88rka",
            "parent": "t1_hk7o5nz",
            "ans": "Absolutely agree, technical skills need to be evaluated, but in an interview with a riddle is not a great way to do this. \n\nWhat we try to assess in an interview is what the candidate does with ambiguous problems, how aware they are of assumptions and how well they communicate about them. We also want to see if we can push them to asking for help.",
            "score": 3,
            "que": "I've had candidates with good looking resumes be unable to tell me the definition of a p-value and 'portfolios' don't really exist for people in my industry.  Some technical evaluation is absolutely necessary."
        },
        {
            "id": "hk7ts3d",
            "parent": "t1_hk7o5nz",
            "ans": "If you need to attach a code name to a particular tail integral of probability density, the p-value that you're gonna abuse and misinterpret your calculation is huge. Or small? Or 5% that you're not absolutely wrong? Ah, f\\* it!",
            "score": 4,
            "que": "I've had candidates with good looking resumes be unable to tell me the definition of a p-value and 'portfolios' don't really exist for people in my industry.  Some technical evaluation is absolutely necessary."
        },
        {
            "id": "hkad8sl",
            "parent": "t1_hk7o5nz",
            "ans": "The last time I did p-values was when I taught stats at a university during grad school. I don't remember that stuff from X years ago. I have never used it in a setting outside of a classroom and even then it was like 1 question on an exam.\n\nIf you're using p-values as a data scientist and you're not in clinical trials then you're probably doing something wrong.\n\nHint: if you think you need a/b testing outside of academia and clinical trials what you really need is optimization. And optimization does not involve p-values.",
            "score": 1,
            "que": "I've had candidates with good looking resumes be unable to tell me the definition of a p-value and 'portfolios' don't really exist for people in my industry.  Some technical evaluation is absolutely necessary."
        },
        {
            "id": "hkarkgk",
            "parent": "t1_hk8o3iq",
            "ans": "Or we could rename Data Science into all the areas it's an umbrella term for - Statistician, Data Analyst, Software Engineer, Machine Learning Researcher, ML Engineer, etc\n\nWould definitely be interested to see this but I feel like it would be way more informative split up that way",
            "score": 3,
            "que": "Someone should study the best predictors for good data scientist if it hasn't been done already. That should be the natural why a data scientist should look at this. Granted there would be problems with data quantity and quality and what to use as measures, etc. but that's kinda what we expect with many situations data scientists encounter. \n\nFWIW, Google studied the usefulness of its brain teasers during interviews: [Google Finally Admits That Its Infamous Brainteasers Were Completely Useless for Hiring](https://www.theatlantic.com/business/archive/2013/06/google-finally-admits-that-its-infamous-brainteasers-were-completely-useless-for-hiring/277053/)"
        },
        {
            "id": "hk8h83h",
            "parent": "t1_hk8fn2h",
            "ans": "Behave in a way that doesn't require translation,  supervision or diplomacy when interacting with non-specialists or management.",
            "score": 8,
            "que": "Socially conscious?  Oh, do you mean \u201chave manners?\u201d"
        },
        {
            "id": "hk92748",
            "parent": "t1_hk8fn2h",
            "ans": "\"have manners\" is such an overloaded term. \n\nWhat's good manners in one cultural group are bad manners in another. \n\nA disproportionate chunk of people screaming about manners... are too self-righteous for my tastes.",
            "score": 1,
            "que": "Socially conscious?  Oh, do you mean \u201chave manners?\u201d"
        },
        {
            "id": "hk7g5lw",
            "parent": "t1_hk733o1",
            "ans": "What?  You don't like the endless stream of Fake Positivity that overwhelms the site?  If you keep complaining we're going to have to give you another \"Interviewee didn't hold the elevator and I was the CEO!!\"-story.",
            "score": 168,
            "que": "LinkedIn is such a crap hole"
        },
        {
            "id": "hk8qb6i",
            "parent": "t1_hk733o1",
            "ans": "It's great as a job search tool. It's fucking hideous as social media.",
            "score": 16,
            "que": "LinkedIn is such a crap hole"
        },
        {
            "id": "hk8y7q6",
            "parent": "t1_hk733o1",
            "ans": "Linkedin is strictly for letting recruiters find me and connecting with colleagues from old jobs I like. Site is very facebook like if you let it be with the scrolling and all that nonsense.",
            "score": 8,
            "que": "LinkedIn is such a crap hole"
        },
        {
            "id": "hk7aqcz",
            "parent": "t1_hk733o1",
            "ans": "All social media are.",
            "score": 17,
            "que": "LinkedIn is such a crap hole"
        },
        {
            "id": "hk8gy6o",
            "parent": "t1_hk88uf4",
            "ans": "Also the more senior you get the more \"being able to speak well\" is actually a job requirement.",
            "score": 23,
            "que": "[deleted]"
        },
        {
            "id": "hkc7koj",
            "parent": "t1_hk88uf4",
            "ans": "It's like [this guy](https://i.redd.it/7w1rw8bgd4z71.jpg). He seems perfectly competent, but so many of these people seem to have impressive jobs but also spend half their day writing content for LinkedIn...",
            "score": 3,
            "que": "[deleted]"
        },
        {
            "id": "hkd9s2i",
            "parent": "t1_hk7p18u",
            "ans": "I think i know whom you are talking about, the seemingly extremely unqualified one",
            "score": 1,
            "que": "Also that amazon chick who pioneered some AI thing at amazon"
        },
        {
            "id": "hk8279o",
            "parent": "t1_hk81c6p",
            "ans": "bayes theorem, lots of stuff about the binomial distribution. some expectations/variance algebra and basic derivations. experimental design and causal inference and variance reduction methods related to that. threats to validity in observational and experimental settings. human coding reliability measurement. imbalanced classification and performance evaluation. nonparametric variance estimation, spillover effects, etc. \n\npretty wide array of things in general but the core theory stuff i found was both basic and pretty focused across interviews. like with leetcode type interviews if you know the basic theory at a high undergrad level (for math-stat in this case) that part of the interview won't trouble you.",
            "score": 32,
            "que": "What were some of the actual questions you got asked?"
        },
        {
            "id": "hk801w1",
            "parent": "t1_hk7yjt5",
            "ans": "You don't have to value one and not the other, or even one over the other.\n\nBut having someone demonstrate their ability to apply probability theory to unfamiliar problems is a great way to see both how strong their understanding is, and how good at problem solving they are. You can even use the opportunity to see how well they work with others or criticisms by asking about their thought process and suggesting alternatives and whatnot.\n\nThat said, I don't think they should only give you a few minutes, depending on the difficulty of the question. I'd say give em the question or questions and a half hour or hour to complete them, and regroup to discuss them.",
            "score": 2,
            "que": "Unexpected questions about dropping eggs and breaking plates are not going to tell you anything about their knowledge of probability. Especially when given only a few minutes to answer. Ask them to explain a few advanced probability/statistical concepts. I will never understand the logic behind prioritizing childish problems with no practical application over actual knowledge and experience."
        },
        {
            "id": "hk7x9jh",
            "parent": "t1_hk7svtd",
            "ans": "I just cannot imagine someone who wants to be a data scientist but doesn't want to solve probability problems. Like... that's what being a data scientist *is*.\n\nI'd honestly want a job more if their interview process would weed out the \"data scientists\" that are just good at BS'ing their way in without much actual knowledge of the tools they're using.",
            "score": 18,
            "que": "Yea, but it's too hard and requires actual thinking. Doesn't everybody want a job where their brains are half asleep or in a distant happy place most of the time? For what the man pays, it's only fair."
        },
        {
            "id": "hk7npt8",
            "parent": "t1_hk7ez2g",
            "ans": "I'm always surprised when people say they don't use stats or maths in their DS work. Do they just blindly import their favourite classifier from sklearn into a jupyter notebook and hope for the best? My grandma could do that, and probably with 100% more heart and flower emojis.",
            "score": 25,
            "que": "[deleted]"
        },
        {
            "id": "hk7kie7",
            "parent": "t1_hk7ez2g",
            "ans": "That sounds like a problem with companies labeling positions incorrectly. Not a problem with asking data scientists to demonstrate their understanding of probability.",
            "score": 12,
            "que": "[deleted]"
        },
        {
            "id": "hk7jhmc",
            "parent": "t1_hk7ez2g",
            "ans": "But the discussion is about 'true' Data Scientists not Data Analysts anyways",
            "score": 6,
            "que": "[deleted]"
        },
        {
            "id": "hk7s7r9",
            "parent": "t1_hk7ez2g",
            "ans": "Thats BS and even for a data analyst positions you should be familiar with probability.  \n\nI have seen DS make mistakes where they do an analysis where they claim some plot show X when you could recreate the plot with just their analysis and input noise from a beta or uniform random distribution. The reason this wasnt obvious to the DS is because probability and design for analysis is so undervalued",
            "score": 2,
            "que": "[deleted]"
        },
        {
            "id": "hk7vu3v",
            "parent": "t1_hk7ez2g",
            "ans": "When people make statements like this it means they're just unaware that they personally don't have the skills to do more advanced work and think that applies to everybody.",
            "score": 1,
            "que": "[deleted]"
        },
        {
            "id": "hkjheun",
            "parent": "t1_hkaf4y0",
            "ans": "[deleted]",
            "score": 2,
            "que": "I am an expert in data mining, machine learning and AI. I know fuck all about probability (sure I did some undergrad & graduate coursework but I can't remember most of it).\n\nI don't really care about probability because none of the methods I use have any solid theoretical basis in statistics. I have never used any of the statistics knowledge from college in my professional life. And if you're using probability as a data scientist outside of clinical trials I'm fairly confident that you're doing things wrong.\n\nIndustry data science and ML research is ~40-50 years ahead of statistics research. The theory simply hasn't been developed yet. None of the actually useful in the real world methods invented in the past ~40 years have a theory that really proves how they work (as is the case with some older better researched methods).\n\nI know there is a sub category of data scientists that took some statistics coursework and proceed to use the same methods (designed as pedagogical tools to teach a concept/as practical tools for clinical trials or social science) in the industry. Without considering the fact that there are methods that achieve far better results with less effort but were never taught in college due to their low pedagogical value & not being the golden standard in applied statistics for clinical trials/social science quantitative studies (which hasn't changed for ~100 years).\n\nI don't need probability (or any statistics coursework for that matter) to use HDBSCAN, xgboost, autonecoders, matrix profiles etc. or even do ML/data mining research. I'd rather people took more of linear algebra, vector calculus and perhaps dabbled in non-linear optimization and complex network theory.\n\nData science is not statistics. Data scientists are concerned with **representations** of phenomenon. Using TF-IDF for example still doesn't have the statistical theory behind it that explains why it works but anyone that has ever done NLP knows that it's pretty damn effective.\n\n100% of feature engineering I do has no theoretical justification. But it works and it improves results and it brings $$$ to the company. With deep learning the feature engineering is learned from the data and a huge can of worms from a theory standpoint. But it outperforms everything else and you're an idiot if you're not using superior methods and your employer is an idiot for hiring you in the first place.\n\nThere is also a question of whether such theory can be developed in the first place. Many have attempted and it really looks like this modern data science thing doesn't fit in statistics at all and never will fit. Kind of like natural science and mathematics split a few centuries ago because the natural world did not fit into the mathematical world anymore."
        },
        {
            "id": "hl10hct",
            "parent": "t1_hkaf4y0",
            "ans": "Despite this being high downvoted, this is true for folks working actual tech DS jobs. I know my probability theory backwards and forwards (former actuarial), but ive never used any of that shit in real life. Probability theory is some like college freshman course after all...",
            "score": 1,
            "que": "I am an expert in data mining, machine learning and AI. I know fuck all about probability (sure I did some undergrad & graduate coursework but I can't remember most of it).\n\nI don't really care about probability because none of the methods I use have any solid theoretical basis in statistics. I have never used any of the statistics knowledge from college in my professional life. And if you're using probability as a data scientist outside of clinical trials I'm fairly confident that you're doing things wrong.\n\nIndustry data science and ML research is ~40-50 years ahead of statistics research. The theory simply hasn't been developed yet. None of the actually useful in the real world methods invented in the past ~40 years have a theory that really proves how they work (as is the case with some older better researched methods).\n\nI know there is a sub category of data scientists that took some statistics coursework and proceed to use the same methods (designed as pedagogical tools to teach a concept/as practical tools for clinical trials or social science) in the industry. Without considering the fact that there are methods that achieve far better results with less effort but were never taught in college due to their low pedagogical value & not being the golden standard in applied statistics for clinical trials/social science quantitative studies (which hasn't changed for ~100 years).\n\nI don't need probability (or any statistics coursework for that matter) to use HDBSCAN, xgboost, autonecoders, matrix profiles etc. or even do ML/data mining research. I'd rather people took more of linear algebra, vector calculus and perhaps dabbled in non-linear optimization and complex network theory.\n\nData science is not statistics. Data scientists are concerned with **representations** of phenomenon. Using TF-IDF for example still doesn't have the statistical theory behind it that explains why it works but anyone that has ever done NLP knows that it's pretty damn effective.\n\n100% of feature engineering I do has no theoretical justification. But it works and it improves results and it brings $$$ to the company. With deep learning the feature engineering is learned from the data and a huge can of worms from a theory standpoint. But it outperforms everything else and you're an idiot if you're not using superior methods and your employer is an idiot for hiring you in the first place.\n\nThere is also a question of whether such theory can be developed in the first place. Many have attempted and it really looks like this modern data science thing doesn't fit in statistics at all and never will fit. Kind of like natural science and mathematics split a few centuries ago because the natural world did not fit into the mathematical world anymore."
        },
        {
            "id": "iuza5ur",
            "parent": "t1_iuo2pei",
            "ans": "Who said anything about making people answer bullshit combinatorial probability questions?\n\nI specifically said that type of thing shouldn't be done. Did you even read my comment?\n\nWhat I'm saying is that they *should* be tested on core probability concepts, like various forms of bias and how to account for them, data collection strategies, precision vs accuracy, common fallacies and how to identify/avoid them, data interpretation skills, etc.\n\nYa know, the shit that *good* data scientists need to know in order to do their job well.\n\nThe questions you mentioned are fairly reasonable, too.\n\nBut you should absolutely test their basic understanding of the field and important concepts as well. Don't let them bullshit you into giving them a job they're not actually equipped to perform.\n\nIf they don't have a strong understand of probability, they're not likely to be a very good or useful data scientist.",
            "score": 1,
            "que": "Wow, your comment was so cringe that I felt compelled to reply to it a year in the future. \n\nThe vast majority of successful data scientists could not accurately answer some bullshit combinatorial probability question. They are bad, lazy, and ultimately irrelevant questions. The focus should be on business impact, on past projects. How to use data science to get from point A to point B. \n\nOral regurgitation of probability definitions, or even worse making them to calculations on the fly, is just so reprehensible."
        },
        {
            "id": "hk80gfm",
            "parent": "t1_hk7xpuh",
            "ans": "Some real probability + statistics interview questions asked by FAANG & Wall Street: [https://www.nicksingh.com/posts/40-probability-statistics-data-science-interview-questions-asked-by-fang-wall-street](https://www.nicksingh.com/posts/40-probability-statistics-data-science-interview-questions-asked-by-fang-wall-street)\n\n(disclaimer tho, it's my own post...sorry for being too promotional but ya asked!)",
            "score": 17,
            "que": "I\u2019d love to know this as well"
        },
        {
            "id": "hkabtmq",
            "parent": "t1_hka81fh",
            "ans": "Coaching actuaries, the expensive way to study interview questions lol",
            "score": 2,
            "que": "Actuarial exams"
        },
        {
            "id": "hk7y3hm",
            "parent": "t1_hk7to9h",
            "ans": "what's even the answer to that? The only thing that I can think of is answering 'not zero'. The probability would vary depending on the size of the data stream and what kind of data it is. It could be highly unique, making the probability lower, for instance.",
            "score": 8,
            "que": "I had an interview loop years ago which started with a legit fair and business-applicable take-home assignment, which they said I passed and that it was excellent.\n\nThe next step was a phone interview.\n\nThem (paraphrased): \"Given a massive data stream that you can't cache, what is the probability of an input datum matching one that you've already seen in the stream?\"\n\nMe: \"Isn't that a network engineering question?\"\n\nInterview ended right after and I was rejected."
        },
        {
            "id": "hk7wqdb",
            "parent": "t1_hk7to9h",
            "ans": "[deleted]",
            "score": 3,
            "que": "I had an interview loop years ago which started with a legit fair and business-applicable take-home assignment, which they said I passed and that it was excellent.\n\nThe next step was a phone interview.\n\nThem (paraphrased): \"Given a massive data stream that you can't cache, what is the probability of an input datum matching one that you've already seen in the stream?\"\n\nMe: \"Isn't that a network engineering question?\"\n\nInterview ended right after and I was rejected."
        },
        {
            "id": "hk7ixib",
            "parent": "t1_hk7czxm",
            "ans": "Dunno, but based on the episode titles there's a lot networking/career stuff and very little science.",
            "score": 4,
            "que": "[deleted]"
        },
        {
            "id": "hk7zxhf",
            "parent": "t1_hk7yvha",
            "ans": "Well the probability that \\*\\*everyone\\*\\* here agrees is near zero, if I had to make a guess.",
            "score": 1,
            "que": "[deleted]"
        },
        {
            "id": "hk784fi",
            "parent": "t1_hk77ama",
            "ans": "I'm not interested in working with people who are afraid to admit when they don't know something and don't know how to look it up.",
            "score": 19,
            "que": "I can't imagine saying this would ever get a favorable response from an interviewer, lol...."
        },
        {
            "id": "hk7j7v0",
            "parent": "t1_hk77ama",
            "ans": "As an interviewer I love that answer. People are not machines. Machines are our slaves. When someone says hey I'm going to use my toolset to solve a problem, rather than just say I can't solve it - they're doing it right. \n\nSomeone on the other hand who just imagines the worst... well they're no use to anyone.",
            "score": 1,
            "que": "I can't imagine saying this would ever get a favorable response from an interviewer, lol...."
        },
        {
            "id": "hk7oyql",
            "parent": "t1_hk7fcbh",
            "ans": "How about knowing the keywords and the theory? I got asked a Bernoulli distribution problem, and couldn't remember the motivating case/solution, but got Bernoulli and that the more general solution exists. Not regurgitating a textbook off the top of your head isn't the goal, you'll only ever know a handful of texts that way. It's knowing which texts to look up that is important, then you've got mental space for hundreds of books' indices.",
            "score": 4,
            "que": "[deleted]"
        },
        {
            "id": "hk9jwth",
            "parent": "t1_hk7fcbh",
            "ans": "> I\u2019m not sure how you show off Google-fu in an interview\n\nThis is really easy if the interviewer will allow it.",
            "score": 1,
            "que": "[deleted]"
        },
        {
            "id": "hk75rwx",
            "parent": "t1_hk72hy8",
            "ans": "Bricks will be much cheaper by the weight. They are easier to produce industrially at large (comparatively by weight).\n\nSome interviews (and some jobs, TBH) are more about your divination capabilities* than your data science skills, as data is not available neither in quantity nor in quality.\n\n\\* it is just logical deduction, like in Sherlock Holmes or The Mentalist.",
            "score": 0,
            "que": "Depends how many feathers and bricks you can buy for 1\u00a3."
        },
        {
            "id": "hk9gt16",
            "parent": "t1_hk75krf",
            "ans": "That was funny.",
            "score": 1,
            "que": "I'm not sure, but I do know that [steel is heavier than feathers](https://www.youtube.com/watch?v=N3bEh-PEk1g)."
        },
        {
            "id": "hk71tuh",
            "parent": "t1_hk70uid",
            "ans": "You replied to your own comment? But it is actually a riddle\u2026 just an easy one\n\nRiddle:\nA question or statement intentionally phrased so as to require ingenuity in ascertaining its answer or meaning.",
            "score": 12,
            "que": "Not a riddle."
        },
        {
            "id": "hk9nt3y",
            "parent": "t1_hk82w1c",
            "ans": "[deleted]",
            "score": 14,
            "que": "The problem is people get nervous in interviews and this causes the brain to shut down. It's a well known psychological behavior. You see it in sports, if one thinks too hard about what they're doing under pressure it causes them to underperform.\n\nThey may know what a p-value is but be unable to explain it in the moment.\n\nSome people are also not neuro-typical, they may have autism or ADHD, and this will make them more likely to fail the question under pressure even if they know it.\n\nI had this happen with a variance/bias question recently. I know the difference, I've used this knowledge before numerous times, I can read up on it and understand it immediately if I forget a few things. However in the moment I couldn't give a good answer because I started getting nervous. I have social anxiety and am on the spectrum.\n\nI've been doing this for 8 years so to be honest a question like \"what's a p-value\" is insulting to a degree. Like what I've done for the last decade doesn't matter in the face of a single oral examination. I didn't fake my masters in mathematics, it's verifiable, why would I be unable to understand variance/bias trade-offs or p-values?\n\nReal work is more like a take-home project. People use references in real work and aren't under pressure to give a specific answer within a single hour or two.\n\nTake-home projects still evaluate for technical competency, they are fairer to neuro-atypical people and I'd argue also more useful evaluations than the typical tech screen simply because it is more like real work. I've used them to hire data scientists numerous times and it always worked out, the people that passed are still employed and outside teams that work with them love them.\n\nYou can always ask for a written explanation of what a p-value is or architect a problem so that if they don't know what it is they will fail."
        },
        {
            "id": "hk8a7cz",
            "parent": "t1_hk82w1c",
            "ans": "I empathize with most of what you're saying, but I don't feel this bit at all:\n\n> I've been doing this for 8 years so to be honest a question like \"what's a p-value\" is insulting to a degree.\n\nI'm ten years into this career, and I've worked with plenty of people that have bounced between jobs for years and still lack baseline technical knowledge. Expert beginners. You must have encountered the same type of long time incompetence in an eight year career, and that's a sufficient reason these foundational definitional questions are asked to everyone. Being insulted about a technical question, it's always struck me as prideful and problematic.\n\nI'm a fan of time bound (on the order of hours) technical take home problems, with a follow up review conversation if the work is promising.",
            "score": 38,
            "que": "The problem is people get nervous in interviews and this causes the brain to shut down. It's a well known psychological behavior. You see it in sports, if one thinks too hard about what they're doing under pressure it causes them to underperform.\n\nThey may know what a p-value is but be unable to explain it in the moment.\n\nSome people are also not neuro-typical, they may have autism or ADHD, and this will make them more likely to fail the question under pressure even if they know it.\n\nI had this happen with a variance/bias question recently. I know the difference, I've used this knowledge before numerous times, I can read up on it and understand it immediately if I forget a few things. However in the moment I couldn't give a good answer because I started getting nervous. I have social anxiety and am on the spectrum.\n\nI've been doing this for 8 years so to be honest a question like \"what's a p-value\" is insulting to a degree. Like what I've done for the last decade doesn't matter in the face of a single oral examination. I didn't fake my masters in mathematics, it's verifiable, why would I be unable to understand variance/bias trade-offs or p-values?\n\nReal work is more like a take-home project. People use references in real work and aren't under pressure to give a specific answer within a single hour or two.\n\nTake-home projects still evaluate for technical competency, they are fairer to neuro-atypical people and I'd argue also more useful evaluations than the typical tech screen simply because it is more like real work. I've used them to hire data scientists numerous times and it always worked out, the people that passed are still employed and outside teams that work with them love them.\n\nYou can always ask for a written explanation of what a p-value is or architect a problem so that if they don't know what it is they will fail."
        },
        {
            "id": "hk8yzit",
            "parent": "t1_hk82w1c",
            "ans": "If you shut down at a fairly trivial question, how are you going to do when you\u2019re on the job?",
            "score": 10,
            "que": "The problem is people get nervous in interviews and this causes the brain to shut down. It's a well known psychological behavior. You see it in sports, if one thinks too hard about what they're doing under pressure it causes them to underperform.\n\nThey may know what a p-value is but be unable to explain it in the moment.\n\nSome people are also not neuro-typical, they may have autism or ADHD, and this will make them more likely to fail the question under pressure even if they know it.\n\nI had this happen with a variance/bias question recently. I know the difference, I've used this knowledge before numerous times, I can read up on it and understand it immediately if I forget a few things. However in the moment I couldn't give a good answer because I started getting nervous. I have social anxiety and am on the spectrum.\n\nI've been doing this for 8 years so to be honest a question like \"what's a p-value\" is insulting to a degree. Like what I've done for the last decade doesn't matter in the face of a single oral examination. I didn't fake my masters in mathematics, it's verifiable, why would I be unable to understand variance/bias trade-offs or p-values?\n\nReal work is more like a take-home project. People use references in real work and aren't under pressure to give a specific answer within a single hour or two.\n\nTake-home projects still evaluate for technical competency, they are fairer to neuro-atypical people and I'd argue also more useful evaluations than the typical tech screen simply because it is more like real work. I've used them to hire data scientists numerous times and it always worked out, the people that passed are still employed and outside teams that work with them love them.\n\nYou can always ask for a written explanation of what a p-value is or architect a problem so that if they don't know what it is they will fail."
        },
        {
            "id": "hk87rjg",
            "parent": "t1_hk82w1c",
            "ans": "People kinda cheat on takehomes though (although I agree they are nicer for other reasons)",
            "score": 4,
            "que": "The problem is people get nervous in interviews and this causes the brain to shut down. It's a well known psychological behavior. You see it in sports, if one thinks too hard about what they're doing under pressure it causes them to underperform.\n\nThey may know what a p-value is but be unable to explain it in the moment.\n\nSome people are also not neuro-typical, they may have autism or ADHD, and this will make them more likely to fail the question under pressure even if they know it.\n\nI had this happen with a variance/bias question recently. I know the difference, I've used this knowledge before numerous times, I can read up on it and understand it immediately if I forget a few things. However in the moment I couldn't give a good answer because I started getting nervous. I have social anxiety and am on the spectrum.\n\nI've been doing this for 8 years so to be honest a question like \"what's a p-value\" is insulting to a degree. Like what I've done for the last decade doesn't matter in the face of a single oral examination. I didn't fake my masters in mathematics, it's verifiable, why would I be unable to understand variance/bias trade-offs or p-values?\n\nReal work is more like a take-home project. People use references in real work and aren't under pressure to give a specific answer within a single hour or two.\n\nTake-home projects still evaluate for technical competency, they are fairer to neuro-atypical people and I'd argue also more useful evaluations than the typical tech screen simply because it is more like real work. I've used them to hire data scientists numerous times and it always worked out, the people that passed are still employed and outside teams that work with them love them.\n\nYou can always ask for a written explanation of what a p-value is or architect a problem so that if they don't know what it is they will fail."
        },
        {
            "id": "hk8j7gb",
            "parent": "t1_hk8bcjn",
            "ans": "Can you help me understand this? I'm not looking for a textbook exact definition.  But rather something like \"you run an experiment and do a statistical test comparing your treatment and control and get a p-value of 0.1 - what does that mean?\".   Could you answer this? I'm looking for something like \"it means that if there is no effect, there's a 10% chance of getting (at least), this much separation between the groups\".",
            "score": 7,
            "que": "I am a Boistatistician with almost 10 years experience - I have led methods papers in propper stats journals mainly on sample size estimation in niche situations.  If you put me on the spot I couldn't give you a rigourous definition of a P-value either. It is a while since I have needed to know.  I could have done when I was straight out of my Masters though, no bother! Am I a better statistican now than I was then? Absolutley."
        },
        {
            "id": "hksbycd",
            "parent": "t1_hk8bcjn",
            "ans": "You wouldn't even be able to give an example to show a working knowledge of what a p value means (so let's not use formalism)? People aren't looking for rigorous definitions a lot of times",
            "score": 1,
            "que": "I am a Boistatistician with almost 10 years experience - I have led methods papers in propper stats journals mainly on sample size estimation in niche situations.  If you put me on the spot I couldn't give you a rigourous definition of a P-value either. It is a while since I have needed to know.  I could have done when I was straight out of my Masters though, no bother! Am I a better statistican now than I was then? Absolutley."
        },
        {
            "id": "hk9urse",
            "parent": "t1_hk89i4r",
            "ans": "The risk is you get a good bullshitter. I worked with plenty of MBAs who could answer that problem with confidence and sound pretty generally aware but I wouldn\u2019t trust to calculate an average in excel.",
            "score": 4,
            "que": "Instead if asking about p-values, I tend to ask candidates how they know their model is connected to reality, and how they would explain that to a business client."
        },
        {
            "id": "hkarkxi",
            "parent": "t1_hk89i4r",
            "ans": "I like that.  A lot of model building is validation and testing, so it allows one to show their experience.",
            "score": 1,
            "que": "Instead if asking about p-values, I tend to ask candidates how they know their model is connected to reality, and how they would explain that to a business client."
        },
        {
            "id": "hk7ywms",
            "parent": "t1_hk7xsbk",
            "ans": "\\*p-value threshold is what you are looking for I think, not p-value. And anyone familiar with the history of it should understand that it is a judgement call, but because it is such a widely used concept it has... well, fallen away.",
            "score": 16,
            "que": "[deleted]"
        },
        {
            "id": "hk8vb11",
            "parent": "t1_hk7xsbk",
            "ans": "Isn't this why we went away from p-value thresholds (e.g., significant at a p-value of 0.05) as a single way to relay complex information? For what it's worth, in my stats degree we pretty much always communicated out the effect size, confidence interval, and p-value.",
            "score": 3,
            "que": "[deleted]"
        },
        {
            "id": "hk8zuk2",
            "parent": "t1_hk7xsbk",
            "ans": "It's not an arbitrary number, it has a basis in probability. The alpha-level of your test is relatively arbitrary, but is, in practice, kept at a low level.",
            "score": 1,
            "que": "[deleted]"
        },
        {
            "id": "hk85kv6",
            "parent": "t1_hk7xsbk",
            "ans": "[deleted]",
            "score": 0,
            "que": "[deleted]"
        },
        {
            "id": "hkar9ua",
            "parent": "t1_hk7xsbk",
            "ans": "Kind of.  If your experiment is well defined then you might be able to identify an ideal p-value for the experiment.  The p-value should change based on multiple factors.  The challenge is when you're exploring something new so an established obvious p-value isn't there yet and you have to default to 0.05 or similar depending on the sample size.\n\nKeeping in mind the p-value is for identifying if two studies are considered the same, eg did the medicine do anything?  It depends on what industry you're in, but imo there is either going to be a large data difference or a small one, so in my case having a \"perfect\" p-value hasn't been necessary thankfully.  It's nice when changes in data are obvious.",
            "score": 1,
            "que": "[deleted]"
        },
        {
            "id": "hk8kn8k",
            "parent": "t1_hk88rka",
            "ans": "Is asking basic, stat 101 questions a riddle, though?",
            "score": 8,
            "que": "Absolutely agree, technical skills need to be evaluated, but in an interview with a riddle is not a great way to do this. \n\nWhat we try to assess in an interview is what the candidate does with ambiguous problems, how aware they are of assumptions and how well they communicate about them. We also want to see if we can push them to asking for help."
        },
        {
            "id": "hk8kkpb",
            "parent": "t1_hk7ts3d",
            "ans": "I don't understand - how would you decide whether the difference between the mean of two groups is likely driven by your intervention or is just due to noise? Yes, the threshold can be arbitrary and it's silly to change your thinking based on p=0.49 vs p=0.51 but this does not mean they a p-value is uninformative. It's a metric that can be used to guide decision making.  Making sure it is used and interpreted correctly is a duty of the data scientist.",
            "score": 6,
            "que": "If you need to attach a code name to a particular tail integral of probability density, the p-value that you're gonna abuse and misinterpret your calculation is huge. Or small? Or 5% that you're not absolutely wrong? Ah, f\\* it!"
        },
        {
            "id": "hkas0a2",
            "parent": "t1_hkad8sl",
            "ans": "I feel you.  11 years as a data scientist I've never used a p-value either.  However, it's useful to remember *why* a tool is beneficial, so you can relearn it in the rare edge case it can help.\n\nA p-value is useful when performing an experiment.  Instead of blindly collecting data and doing analytics or building models on it, you can help orchestrate how new data will be collected to test outcomes.  Experiments can be helpful in a lot of situations.\n\nWhen you create an experiment, you can have a control, and suddenly a p-value is value-able (pun intended).",
            "score": 1,
            "que": "The last time I did p-values was when I taught stats at a university during grad school. I don't remember that stuff from X years ago. I have never used it in a setting outside of a classroom and even then it was like 1 question on an exam.\n\nIf you're using p-values as a data scientist and you're not in clinical trials then you're probably doing something wrong.\n\nHint: if you think you need a/b testing outside of academia and clinical trials what you really need is optimization. And optimization does not involve p-values."
        },
        {
            "id": "hk7ge28",
            "parent": "t1_hk7g5lw",
            "ans": "Hahah. The Ass Kissing is Nauseating.",
            "score": 35,
            "que": "What?  You don't like the endless stream of Fake Positivity that overwhelms the site?  If you keep complaining we're going to have to give you another \"Interviewee didn't hold the elevator and I was the CEO!!\"-story."
        },
        {
            "id": "hk7tuuy",
            "parent": "t1_hk7g5lw",
            "ans": "/r/RecruitingHell",
            "score": 10,
            "que": "What?  You don't like the endless stream of Fake Positivity that overwhelms the site?  If you keep complaining we're going to have to give you another \"Interviewee didn't hold the elevator and I was the CEO!!\"-story."
        },
        {
            "id": "hk8s2xt",
            "parent": "t1_hk7g5lw",
            "ans": "I wish just one person gave real advice and stores on LinkedIn with no fluff, I have never seen it.",
            "score": 4,
            "que": "What?  You don't like the endless stream of Fake Positivity that overwhelms the site?  If you keep complaining we're going to have to give you another \"Interviewee didn't hold the elevator and I was the CEO!!\"-story."
        },
        {
            "id": "hk9nhuj",
            "parent": "t1_hk7g5lw",
            "ans": "Some connection of mine was a dev who was laid off from a tech company that made record profits. This dummy THANKED the company in some post. Thank God the rest of his connections in a much more professional way told him to stop choking on the corporate weenie",
            "score": 4,
            "que": "What?  You don't like the endless stream of Fake Positivity that overwhelms the site?  If you keep complaining we're going to have to give you another \"Interviewee didn't hold the elevator and I was the CEO!!\"-story."
        },
        {
            "id": "hk917iu",
            "parent": "t1_hk7g5lw",
            "ans": "Actually that happened to me. But I knew by coincidence that the guy is managing director, so I better held the elevator.",
            "score": 1,
            "que": "What?  You don't like the endless stream of Fake Positivity that overwhelms the site?  If you keep complaining we're going to have to give you another \"Interviewee didn't hold the elevator and I was the CEO!!\"-story."
        },
        {
            "id": "hk7badx",
            "parent": "t1_hk7aqcz",
            "ans": "LinkedIn especially so because of the corporate class hierarchy.",
            "score": 26,
            "que": "All social media are."
        },
        {
            "id": "hk9v72h",
            "parent": "t1_hk8gy6o",
            "ans": "How do such people not manage to get exposed, especially in senior positions?",
            "score": 0,
            "que": "Also the more senior you get the more \"being able to speak well\" is actually a job requirement."
        },
        {
            "id": "hkdbomb",
            "parent": "t1_hkd9s2i",
            "ans": "That was the impression I got. It's like how in the world did you get to this position. But hey maybe in satly I didnt get a cush job myself",
            "score": 2,
            "que": "I think i know whom you are talking about, the seemingly extremely unqualified one"
        },
        {
            "id": "hk857jv",
            "parent": "t1_hk8279o",
            "ans": "Thanks for the elaborate answer!",
            "score": 1,
            "que": "bayes theorem, lots of stuff about the binomial distribution. some expectations/variance algebra and basic derivations. experimental design and causal inference and variance reduction methods related to that. threats to validity in observational and experimental settings. human coding reliability measurement. imbalanced classification and performance evaluation. nonparametric variance estimation, spillover effects, etc. \n\npretty wide array of things in general but the core theory stuff i found was both basic and pretty focused across interviews. like with leetcode type interviews if you know the basic theory at a high undergrad level (for math-stat in this case) that part of the interview won't trouble you."
        },
        {
            "id": "hk8c4vg",
            "parent": "t1_hk801w1",
            "ans": "You do need to prioritize one over the other if you\u2019re giving them an hour. You don\u2019t have unlimited time to interview someone and it\u2019s counterproductive to drag it out. Especially if you\u2019re interviewing someone in multiple rounds. Applying probability to unexpected problems that have no real world application will not give you any real understanding of that person\u2019s ability to do their job. I\u2019ve seen way too many people hired after doing well on brain teasers only to be horrible at applying statistical concepts in the workplace. In the real world, you aren\u2019t solving problems that you see in stats 101 textbooks. And their ability to go about them isn\u2019t telling you anything about their true understanding of advanced probability. Nearly every time I\u2019ve seen a candidate struggle with these questions, it is because they don\u2019t understand the problem they\u2019re being asked. And why would they? It will absolutely never come up in their life outside of an interview.",
            "score": 6,
            "que": "You don't have to value one and not the other, or even one over the other.\n\nBut having someone demonstrate their ability to apply probability theory to unfamiliar problems is a great way to see both how strong their understanding is, and how good at problem solving they are. You can even use the opportunity to see how well they work with others or criticisms by asking about their thought process and suggesting alternatives and whatnot.\n\nThat said, I don't think they should only give you a few minutes, depending on the difficulty of the question. I'd say give em the question or questions and a half hour or hour to complete them, and regroup to discuss them."
        },
        {
            "id": "hk7z7fn",
            "parent": "t1_hk7x9jh",
            "ans": "Depends on the job. A lot of jobs want a hybrid person who\u2019s both a software and data engineer in addition to being a data scientist. The hardcore math people usually fail pretty hard in those environments.",
            "score": 17,
            "que": "I just cannot imagine someone who wants to be a data scientist but doesn't want to solve probability problems. Like... that's what being a data scientist *is*.\n\nI'd honestly want a job more if their interview process would weed out the \"data scientists\" that are just good at BS'ing their way in without much actual knowledge of the tools they're using."
        },
        {
            "id": "hk85wum",
            "parent": "t1_hk7x9jh",
            "ans": "That depends. I'd argue data science benefits more from information theory, however, probability can be built using information theory so I guess it's about the same.",
            "score": 4,
            "que": "I just cannot imagine someone who wants to be a data scientist but doesn't want to solve probability problems. Like... that's what being a data scientist *is*.\n\nI'd honestly want a job more if their interview process would weed out the \"data scientists\" that are just good at BS'ing their way in without much actual knowledge of the tools they're using."
        },
        {
            "id": "hk7y45c",
            "parent": "t1_hk7npt8",
            "ans": "Exactly!!\n\nIt's people that basically just know some programming and have read about a few cool ML algorithms and are able to convince hiring managers that they're data scientists now.\n\nIt's people like that who ruin the reputation of data science, too, because they'll waltz into a company with big promises and a fancy model and will ultimately fail because they weren't basing it on good data, overfit it, or any number of other problems. And now that company will feel like they've been duped and will think DS is a bunch of bullshit",
            "score": 7,
            "que": "I'm always surprised when people say they don't use stats or maths in their DS work. Do they just blindly import their favourite classifier from sklearn into a jupyter notebook and hope for the best? My grandma could do that, and probably with 100% more heart and flower emojis."
        },
        {
            "id": "hk823r8",
            "parent": "t1_hk7npt8",
            "ans": "Well you say that but when you understand the stats, your process just becomes\n\n> ~~blindly~~ import your favourite classifier from sklearn into a jupyter notebook.\n\nin 90% of cases!",
            "score": 4,
            "que": "I'm always surprised when people say they don't use stats or maths in their DS work. Do they just blindly import their favourite classifier from sklearn into a jupyter notebook and hope for the best? My grandma could do that, and probably with 100% more heart and flower emojis."
        },
        {
            "id": "hk8cwly",
            "parent": "t1_hk7npt8",
            "ans": "I bet they do but since they know how to use docker, kubernetes, Hadoop, AWS or GCP, they will get the job over someone who just knows stats and none of the other technical skills.\n\n\n-a stats graduate who realized that my undergrad degree is perfect on paper but needs to become a hard core programmer too",
            "score": 3,
            "que": "I'm always surprised when people say they don't use stats or maths in their DS work. Do they just blindly import their favourite classifier from sklearn into a jupyter notebook and hope for the best? My grandma could do that, and probably with 100% more heart and flower emojis."
        },
        {
            "id": "hk7yqvd",
            "parent": "t1_hk7s7r9",
            "ans": "Oooo design of analysis is a big one!\n\nI've seen people do this, and did it myself as an intern, but so many data analysts/scientists won't really have a designed plan or approach to a problem, and will just throw a bunch of different models at a problem until they get the right numbers coming out of it.\n\nOnly to then, of course, find out how shitty their model is because they basically just overfit it to the data and it doesn't actually predict *anything*.",
            "score": 1,
            "que": "Thats BS and even for a data analyst positions you should be familiar with probability.  \n\nI have seen DS make mistakes where they do an analysis where they claim some plot show X when you could recreate the plot with just their analysis and input noise from a beta or uniform random distribution. The reason this wasnt obvious to the DS is because probability and design for analysis is so undervalued"
        },
        {
            "id": "hk8evxb",
            "parent": "t1_hk7vu3v",
            "ans": "Yea, classic case of projection.",
            "score": 1,
            "que": "When people make statements like this it means they're just unaware that they personally don't have the skills to do more advanced work and think that applies to everybody."
        },
        {
            "id": "hkjifrf",
            "parent": "t1_hkjheun",
            "ans": "Since you're so smart, please write up your thoughts and publish them. This will be the most influential paper... ever. You'll put Einstein to shame.\n\nYou're just chaining up some random words that sound fancy. Go read Leo Breiman's papers, he literally says in multiple of his later papers that his work goes beyond statistics and criticizes the field of statistics for being so inflexible. He even has a paper explaining how this came to be historically and what are the reasons that this happened. Which is why venues like KDD, NeurIPS etc. and fields like Data Mining and Machine Learning came along. He was the one that lead to their creation.",
            "score": 0,
            "que": "[deleted]"
        },
        {
            "id": "hk7zbbk",
            "parent": "t1_hk7y3hm",
            "ans": "I forget the exact question (which is relevant when doing a riddle) but IIRC the answer was similar in concept to the [birthday paradox](https://en.wikipedia.org/wiki/Birthday_problem) which I would have been glad to talk about if it wasn't obfuscated.",
            "score": 3,
            "que": "what's even the answer to that? The only thing that I can think of is answering 'not zero'. The probability would vary depending on the size of the data stream and what kind of data it is. It could be highly unique, making the probability lower, for instance."
        },
        {
            "id": "hkavfl8",
            "parent": "t1_hk7y3hm",
            "ans": "OK another shot at what the problem probably is\u2026.\n\nAssume IID data emitted from set of cardinality N with *uniform* probability (BIG assumption) \u2026\n\n\nProbability that previous datum fails to match query is (N-1)/N = R \n\n assuming IID probabilities failure to match in M observations is R^M so probability of a match or more  is 1-R^M",
            "score": 2,
            "que": "what's even the answer to that? The only thing that I can think of is answering 'not zero'. The probability would vary depending on the size of the data stream and what kind of data it is. It could be highly unique, making the probability lower, for instance."
        },
        {
            "id": "hkatyca",
            "parent": "t1_hk7y3hm",
            "ans": "yes, those would be important criteria.   \n\nI would ask about the cardinality of distinct data and the definition of \u201cequal\u201d, \n\nThen ask if an IID assumption is appropriate, and if so, make a WAG based on a Poisson process with an certain rate parameter.\n\nSo you could make some kind of estimate after various baseline assumptions.\n\nBefore trying a computation I would walk through various asymptotic limits, say starting from Bernoulli binaries (yeah you would see a repeated bit quickly).\n\nI think in truth the problem is an encoded \u201csampling with replacement bootstrap\u201d question\n\nIt\u2019s not a great question but finding a math problem silently embedded in other issues is what data scientists should be able to do sometimes.",
            "score": 1,
            "que": "what's even the answer to that? The only thing that I can think of is answering 'not zero'. The probability would vary depending on the size of the data stream and what kind of data it is. It could be highly unique, making the probability lower, for instance."
        },
        {
            "id": "hk80521",
            "parent": "t1_hk7wqdb",
            "ans": "As a now-current data scientist I agree data flow/data engineering is a relevant part of the role, but if there's ever a case where there's *too much* data such that there are additional constraints I'll flag a network engineer to ensure it's done correctly.",
            "score": 3,
            "que": "[deleted]"
        },
        {
            "id": "hk80s6v",
            "parent": "t1_hk7zxhf",
            "ans": "[deleted]",
            "score": 4,
            "que": "Well the probability that \\*\\*everyone\\*\\* here agrees is near zero, if I had to make a guess."
        },
        {
            "id": "hk792b5",
            "parent": "t1_hk784fi",
            "ans": "[deleted]",
            "score": 10,
            "que": "I'm not interested in working with people who are afraid to admit when they don't know something and don't know how to look it up."
        },
        {
            "id": "hk7ecrp",
            "parent": "t1_hk784fi",
            "ans": "I think the problem is you still weren't able to demonstrate anything. It's easier to say you could look it up than to do it successfully.\n\nSo, in the scheme of things, your interview will be dinged for that, compared to someone that was able to do it. Both will be miles ahead of someone that tries to confidently BS and gets it wrong.",
            "score": 3,
            "que": "I'm not interested in working with people who are afraid to admit when they don't know something and don't know how to look it up."
        },
        {
            "id": "hk8au1q",
            "parent": "t1_hk784fi",
            "ans": "I never said that was the alternative. It's just far more valuable to rely on your problem solving skills and experience to at least try to work through a technical issue, considering the interviewer is probably more interested in your thought process than your conclusion.\n\nIf your approach to a technical question is instead to say \"I can google it in seconds\", then I don't think this gives the interviewer any indication into how you will reason through problems on the job.",
            "score": 0,
            "que": "I'm not interested in working with people who are afraid to admit when they don't know something and don't know how to look it up."
        },
        {
            "id": "hk7feo2",
            "parent": "t1_hk75rwx",
            "ans": "[deleted]",
            "score": 7,
            "que": "Bricks will be much cheaper by the weight. They are easier to produce industrially at large (comparatively by weight).\n\nSome interviews (and some jobs, TBH) are more about your divination capabilities* than your data science skills, as data is not available neither in quantity nor in quality.\n\n\\* it is just logical deduction, like in Sherlock Holmes or The Mentalist."
        },
        {
            "id": "hk73g1p",
            "parent": "t1_hk71tuh",
            "ans": "They forgot to log into their second account for karma farming",
            "score": 12,
            "que": "You replied to your own comment? But it is actually a riddle\u2026 just an easy one\n\nRiddle:\nA question or statement intentionally phrased so as to require ingenuity in ascertaining its answer or meaning."
        },
        {
            "id": "hk72gn9",
            "parent": "t1_hk71tuh",
            "ans": "I feel like riddles are more thought provoking. Good to know.",
            "score": -2,
            "que": "You replied to your own comment? But it is actually a riddle\u2026 just an easy one\n\nRiddle:\nA question or statement intentionally phrased so as to require ingenuity in ascertaining its answer or meaning."
        },
        {
            "id": "hkaqhp1",
            "parent": "t1_hk9nt3y",
            "ans": "ADHD brains don't work like that tho, we just forget everything all the time. This doesn't actually affect our work because we edit 500x more than the average person, but it seems impossible to convey that concept in the interview without coming off like we're making excuses. \n\nI don't need to remember almost anything to do my job correctly - what matters is the core understanding and the ability to figure stuff out, and both are there. It's just the details that get mixed up in the moment. (For the record I'm more of a programmer than a mathematician but I never struggled with math when given the time I needed).\n\nHonestly looking for suggestions here because I've hit the same issue so many times and I'm at a loss at this point (and have a technical interview coming up as a bonus). Do I tell them I have ADHD? Not sure what else I can do",
            "score": 12,
            "que": "[deleted]"
        },
        {
            "id": "hkad3fb",
            "parent": "t1_hk9nt3y",
            "ans": "I once saw a PhD defence where a committee member asked the student what a P value meant (after he had reported several). It stumped him.\n\nFoundational questions are wholly appropriate.",
            "score": 9,
            "que": "[deleted]"
        },
        {
            "id": "hk9kvsk",
            "parent": "t1_hk8a7cz",
            "ans": "Exactly. It depends on the role, but for many of the positions that I am hiring for I need people who can explain things like a p value to other stakeholders (either our clients, or business stakeholders). It's totally reasonable to expect that someone *outside* of the data science group would ask them that question, and I need to know how they are going to respond to it.",
            "score": 13,
            "que": "I empathize with most of what you're saying, but I don't feel this bit at all:\n\n> I've been doing this for 8 years so to be honest a question like \"what's a p-value\" is insulting to a degree.\n\nI'm ten years into this career, and I've worked with plenty of people that have bounced between jobs for years and still lack baseline technical knowledge. Expert beginners. You must have encountered the same type of long time incompetence in an eight year career, and that's a sufficient reason these foundational definitional questions are asked to everyone. Being insulted about a technical question, it's always struck me as prideful and problematic.\n\nI'm a fan of time bound (on the order of hours) technical take home problems, with a follow up review conversation if the work is promising."
        },
        {
            "id": "hk8joyc",
            "parent": "t1_hk8a7cz",
            "ans": "Exactly. If someone asks me a trivial question, I know why they are doing this and that it's nothing personal.  Being offended makes me think the person is some sort of diva (like a movie star that won't audition for a role - \"do you know who I AM?\").",
            "score": 12,
            "que": "I empathize with most of what you're saying, but I don't feel this bit at all:\n\n> I've been doing this for 8 years so to be honest a question like \"what's a p-value\" is insulting to a degree.\n\nI'm ten years into this career, and I've worked with plenty of people that have bounced between jobs for years and still lack baseline technical knowledge. Expert beginners. You must have encountered the same type of long time incompetence in an eight year career, and that's a sufficient reason these foundational definitional questions are asked to everyone. Being insulted about a technical question, it's always struck me as prideful and problematic.\n\nI'm a fan of time bound (on the order of hours) technical take home problems, with a follow up review conversation if the work is promising."
        },
        {
            "id": "hlrtm8k",
            "parent": "t1_hk8a7cz",
            "ans": "The point is the questions are pointless. I can remind myself of what a p-value is in 30 seconds if I read google. If you are going to ask me what a p-value is then allow me to google it as I would in a job, or ask me how I would apply a p-value instead of asking for the definition.",
            "score": 1,
            "que": "I empathize with most of what you're saying, but I don't feel this bit at all:\n\n> I've been doing this for 8 years so to be honest a question like \"what's a p-value\" is insulting to a degree.\n\nI'm ten years into this career, and I've worked with plenty of people that have bounced between jobs for years and still lack baseline technical knowledge. Expert beginners. You must have encountered the same type of long time incompetence in an eight year career, and that's a sufficient reason these foundational definitional questions are asked to everyone. Being insulted about a technical question, it's always struck me as prideful and problematic.\n\nI'm a fan of time bound (on the order of hours) technical take home problems, with a follow up review conversation if the work is promising."
        },
        {
            "id": "hkd5zn0",
            "parent": "t1_hk8yzit",
            "ans": "Depends on the work environment. What you see from split second definition questions in a interview situation is a memory recall exercise under high pressure. If that is what is needed on the job, that that's fine.",
            "score": 1,
            "que": "If you shut down at a fairly trivial question, how are you going to do when you\u2019re on the job?"
        },
        {
            "id": "hk892on",
            "parent": "t1_hk87rjg",
            "ans": "How would you define cheating?\n\nBusiness usually cares more about you actually figuring something out, not how you did it.\n\nIf it's a common problem I could see cheating being akin to plagiarism, and you avoid it by baking your own problem rather than using one you found in a blog post or something.",
            "score": 13,
            "que": "People kinda cheat on takehomes though (although I agree they are nicer for other reasons)"
        },
        {
            "id": "hkaqxzh",
            "parent": "t1_hk87rjg",
            "ans": "What is programming these days if not strategic use of stack overflow tho? Ask them to explain the code after and there's your filter",
            "score": 2,
            "que": "People kinda cheat on takehomes though (although I agree they are nicer for other reasons)"
        },
        {
            "id": "hk8ysax",
            "parent": "t1_hk8j7gb",
            "ans": "Statistician here. A p-value is the probability of getting a result as or more extreme as your data under the conditions of the null hypothesis. Essentially you are saying, \"if the null hypothesis is true and is actually what's going on, how strange is my data?\" If your data is pretty consistent with the situation under the null hypothesis, then you get a larger p-value because that reflects that the probability of your situation occurring is quite high. If your data is not consistent with the situation under the null hypothesis, then you get a smaller p-value because that reflects that the probability of your situation occurring is quite low.\n\nWhat to do with the information you get from your p-value is a whole topic of debate. This is where alpha level, Type I error rate, significance, etc. show up. How do you use your p-value to decide what to do? In most of the non-stats world, you compare it to some significance level and use that to decide whether to accept the null hypothesis or reject it in favor of the alternative hypothesis (which is you saying that you have concluded that the alternative hypothesis is a better explanation for your data than the null hypothesis, not that the alternative hypothesis is correct). The significance level is arbitrary. If you think about setting your significance level to be 0.5, then you reject the null hypothesis when your p-value is 0.49 and accept it when your p-value is 0.51. But that's a very small difference in those p-values. You had to make the cut-off somewhere, so you end up with these types of splits.\n\nKeep in mind that you actually *didn't* have to make the cut-off somewhere. Non-statisticians want a quick and easy way to make a decision so they've gone crazy with significance levels (especially 0.05) but p-values are not decision making tools. They're being used incorrectly.\n\nMost people fundamentally misunderstand what a p-value measures and they thinks it's P(H0|Data) when it's actually P(Data|H0).\n\n(Note that this is the definition of a frequentist p-value and not a Bayesian p-value.)\n\nEdit: sorry, forgot to answer your actual question.\n\n> get a p-value of 0.1\n\nA p-value of 0.1 means that if you ran your experiment perfectly 1000 times and you satisfied all of the conditions of the statistical test perfectly each of the 1000 times then if the null hypothesis is what's really going on, you would get results as strange or stranger than your about 100 every 1000 experiments. Is this situation unusual enough that you end up deciding to reject the null hypothesis in favor of the alternative hypothesis? A lot of people will say that a p-value of 0.1 isn't small enough because getting your results about 10% of the time under the conditions of the null hypothesis isn't enough evidence to reject the null hypothesis as an explanation.",
            "score": 26,
            "que": "Can you help me understand this? I'm not looking for a textbook exact definition.  But rather something like \"you run an experiment and do a statistical test comparing your treatment and control and get a p-value of 0.1 - what does that mean?\".   Could you answer this? I'm looking for something like \"it means that if there is no effect, there's a 10% chance of getting (at least), this much separation between the groups\"."
        },
        {
            "id": "hk8s6ez",
            "parent": "t1_hk8j7gb",
            "ans": "The answer is simple: It's the probability getting such results (or more extreme ones) under the null hypothesis.",
            "score": 4,
            "que": "Can you help me understand this? I'm not looking for a textbook exact definition.  But rather something like \"you run an experiment and do a statistical test comparing your treatment and control and get a p-value of 0.1 - what does that mean?\".   Could you answer this? I'm looking for something like \"it means that if there is no effect, there's a 10% chance of getting (at least), this much separation between the groups\"."
        },
        {
            "id": "hk91t33",
            "parent": "t1_hk8j7gb",
            "ans": "Ok, I see what you mean.  I thought you would want me to start talking about \"infinate numbers of hypothtical replications\" and the sort. Yes, if you asked me out of the blue I would be able to answer in rough terms.",
            "score": 1,
            "que": "Can you help me understand this? I'm not looking for a textbook exact definition.  But rather something like \"you run an experiment and do a statistical test comparing your treatment and control and get a p-value of 0.1 - what does that mean?\".   Could you answer this? I'm looking for something like \"it means that if there is no effect, there's a 10% chance of getting (at least), this much separation between the groups\"."
        },
        {
            "id": "hk8oir1",
            "parent": "t1_hk8j7gb",
            "ans": "The p-value is basically the probability of something (event/situation) having occurred by random chance. So basically, higher this value, more is the probability that it occurred just by chance. If you look at the flipside now, the lower this value is, the lower the probability that that event/situation occurred by chance, which means you can say, with certain confidence, that X caused Y if you get my drift.\n\nFor eg: \nYou have yearly Data of sales of a local rainwear store. The store owner tells you that sales increases during the monsoon as opposed to others. This will be your null hypothesis. \n\nThen you set your significance level (this decides whether the p value is significant or not). Most commonly used significance level is 95%. \nI'll use this for this example. \n\nInterpretation:\n\nLets consider that whatever analysis you do gives you a p-value of 0.1. Significance threshold is 100%-95%= 5% or 0.05. Now 0.05 < 0.1, thus the causation et al being checked is not significant / most probably occurred by chance. In plain terms, the monsoon does NOT drive sales at this store. \n\nIf the p value is lower than 0.05 in this example, then it most probably did NOT occur by chance. In plain terms, we can say that sales increases during the monsoon.\n\nTLDR: At a predetermined significance level, we can use the p-value from our analysis to ascertain if the causation we're testing occurred by chance or not depending on whether it's more or less than the p-value  derived from the significance threshold.",
            "score": -4,
            "que": "Can you help me understand this? I'm not looking for a textbook exact definition.  But rather something like \"you run an experiment and do a statistical test comparing your treatment and control and get a p-value of 0.1 - what does that mean?\".   Could you answer this? I'm looking for something like \"it means that if there is no effect, there's a 10% chance of getting (at least), this much separation between the groups\"."
        },
        {
            "id": "hkbj0yc",
            "parent": "t1_hkarkxi",
            "ans": "It tends to surface things like, \"this adjuster consistently finds fraud  in almost every claim he evaluates, so our model shows him as a top performer. Oh, that's Dave, he only works two days a week so we only give him easy stuff\".",
            "score": 2,
            "que": "I like that.  A lot of model building is validation and testing, so it allows one to show their experience."
        },
        {
            "id": "hk98f5z",
            "parent": "t1_hk7ywms",
            "ans": "AKA: alpha",
            "score": 2,
            "que": "\\*p-value threshold is what you are looking for I think, not p-value. And anyone familiar with the history of it should understand that it is a judgement call, but because it is such a widely used concept it has... well, fallen away."
        },
        {
            "id": "hk810v8",
            "parent": "t1_hk7ywms",
            "ans": "[deleted]",
            "score": 1,
            "que": "\\*p-value threshold is what you are looking for I think, not p-value. And anyone familiar with the history of it should understand that it is a judgement call, but because it is such a widely used concept it has... well, fallen away."
        },
        {
            "id": "hkaeiq9",
            "parent": "t1_hk8vb11",
            "ans": "In empirical research you can't prove anything. You can only gather more evidence. In academia the threshold for \"hmm, you might be onto something, let's print it and see what others think\" is 5% in social sciences and 5 sigma (so waaaay less than 5%) in particle physics with most other science falling somewhere in between.\n\nIt doesn't **mean** anything except that it's an interesting enough of a result to write it down and share it with others.\n\nIt takes a meta-analysis of dozens of experiments and multiple repeated studies in different situations using different methods to actually accept it as a scientific fact. And this does not involve p-values.",
            "score": 3,
            "que": "Isn't this why we went away from p-value thresholds (e.g., significant at a p-value of 0.05) as a single way to relay complex information? For what it's worth, in my stats degree we pretty much always communicated out the effect size, confidence interval, and p-value."
        },
        {
            "id": "hkbee7f",
            "parent": "t1_hk8zuk2",
            "ans": "It is arbitrary because we do not know the probability of H0 being true, and in most cases we can be almost certain that it is not true (e.g. two medicines with different biomedical mechanisms will never have exactly the same effect). So the conditional probability P(data|H0 is true) is meaningless for decision-making.",
            "score": 1,
            "que": "It's not an arbitrary number, it has a basis in probability. The alpha-level of your test is relatively arbitrary, but is, in practice, kept at a low level."
        },
        {
            "id": "hk87o61",
            "parent": "t1_hk85kv6",
            "ans": "Nooo.\n\nIt tells you the probability of observing data as extreme or more extreme than the data you observed *assuming* the null is true.",
            "score": 6,
            "que": "[deleted]"
        },
        {
            "id": "hkarpl5",
            "parent": "t1_hk8kn8k",
            "ans": "It's a trivia question.  Both trivia questions and riddles have been shown in studies to not correlate to employee performance.  Many companies ban them, eg Google used to give these kinds of questions but since has banned them.",
            "score": 1,
            "que": "Is asking basic, stat 101 questions a riddle, though?"
        },
        {
            "id": "hk8xm22",
            "parent": "t1_hk8kkpb",
            "ans": "> threshold can be arbitrary\n\nThis is the problem.  If you have no grounding from which to derive a non-arbitrary threshold, then p-values are absolutely uninformative.  Put another way, p-values are not universally applicable.",
            "score": 0,
            "que": "I don't understand - how would you decide whether the difference between the mean of two groups is likely driven by your intervention or is just due to noise? Yes, the threshold can be arbitrary and it's silly to change your thinking based on p=0.49 vs p=0.51 but this does not mean they a p-value is uninformative. It's a metric that can be used to guide decision making.  Making sure it is used and interpreted correctly is a duty of the data scientist."
        },
        {
            "id": "hkast7u",
            "parent": "t1_hkas0a2",
            "ans": "What do you need p-values for?\n\nThis type of experimentation cares about practical significance. P-values are about statistical significance.\n\nYou say \"blindly collecting data\". I am 100% sure you're not talking about experiments. You're talking about optimizing against some type of objective but you don't know much about optimization so you default to stats 101 and think \"experiments, hypothesis, p-value\".\n\nTypical XY problem. You focus on the wrong solution to your actual problem.\n\nI have not encountered a situation outside of academia (social sciences) and clinical trials where you'd need statistical tests and p-values. And even then it's mostly for historical reasons. The journals just require you to do p-values and it's not actually the best approach.",
            "score": 1,
            "que": "I feel you.  11 years as a data scientist I've never used a p-value either.  However, it's useful to remember *why* a tool is beneficial, so you can relearn it in the rare edge case it can help.\n\nA p-value is useful when performing an experiment.  Instead of blindly collecting data and doing analytics or building models on it, you can help orchestrate how new data will be collected to test outcomes.  Experiments can be helpful in a lot of situations.\n\nWhen you create an experiment, you can have a control, and suddenly a p-value is value-able (pun intended)."
        },
        {
            "id": "hk8vhzz",
            "parent": "t1_hk8s2xt",
            "ans": "I follow some technical practitioners, every once in a while they have a good article.  But for the most part, it\u2019s fake positivity and other forms of \u201crecruiter detritus\u201d",
            "score": 5,
            "que": "I wish just one person gave real advice and stores on LinkedIn with no fluff, I have never seen it."
        },
        {
            "id": "hk9h766",
            "parent": "t1_hk8s2xt",
            "ans": "I quite like Vin Vashishta's content. I'm not sure I'd call it \"no fluff\", and he absolutely is selling his consulting/coaching services; but if it's fluff he's good at making it feel useful and generally inoffensive.",
            "score": 2,
            "que": "I wish just one person gave real advice and stores on LinkedIn with no fluff, I have never seen it."
        },
        {
            "id": "hl9sml3",
            "parent": "t1_hk8s2xt",
            "ans": "Join tiktok",
            "score": 1,
            "que": "I wish just one person gave real advice and stores on LinkedIn with no fluff, I have never seen it."
        },
        {
            "id": "hk9szeb",
            "parent": "t1_hk9nhuj",
            "ans": "I can\u2019t stand that seam of subservience that seems to be celebrated on LinkedIn.",
            "score": 5,
            "que": "Some connection of mine was a dev who was laid off from a tech company that made record profits. This dummy THANKED the company in some post. Thank God the rest of his connections in a much more professional way told him to stop choking on the corporate weenie"
        },
        {
            "id": "hk91plq",
            "parent": "t1_hk917iu",
            "ans": "*See Reddit, I told you I was going to get another story if the complaining continued!!!*\n\nJust kidding.",
            "score": 2,
            "que": "Actually that happened to me. But I knew by coincidence that the guy is managing director, so I better held the elevator."
        },
        {
            "id": "hk8r4zf",
            "parent": "t1_hk8c4vg",
            "ans": "Probability, in practice, is highly nuanced, but not so tricky for those with a deep understanding. If a candidate struggles to solve a probability riddle, they're likely to struggle applying probability and statistical theory to real world applications.\n\nData science is like word problems in K-12 math. The value is being able to set up the problem from the description, not from calculating the answer once the problem is set up. Knowing how to call an algorithm is of little use if one doesn't understand when or why to call that algorithm.\n\nBeing able to call ML functions is a trivially valuable skill. Knowing how to go from the problem as described by the business owner to an \\\\R/Python script that provides meaningful and useful output, along with knowing how to interpret and explain that output for non-DS stakeholders, is where data scientists add value.\n\nRiddles help separate those with nuanced understanding of probability theory from those without. [It can literally save lives](https://www.deanyeong.com/article/survivorship-bias).",
            "score": -3,
            "que": "You do need to prioritize one over the other if you\u2019re giving them an hour. You don\u2019t have unlimited time to interview someone and it\u2019s counterproductive to drag it out. Especially if you\u2019re interviewing someone in multiple rounds. Applying probability to unexpected problems that have no real world application will not give you any real understanding of that person\u2019s ability to do their job. I\u2019ve seen way too many people hired after doing well on brain teasers only to be horrible at applying statistical concepts in the workplace. In the real world, you aren\u2019t solving problems that you see in stats 101 textbooks. And their ability to go about them isn\u2019t telling you anything about their true understanding of advanced probability. Nearly every time I\u2019ve seen a candidate struggle with these questions, it is because they don\u2019t understand the problem they\u2019re being asked. And why would they? It will absolutely never come up in their life outside of an interview."
        },
        {
            "id": "hk808a4",
            "parent": "t1_hk7z7fn",
            "ans": "That sounds like companies expecting way too much from people, and is a recipe for failure.",
            "score": 5,
            "que": "Depends on the job. A lot of jobs want a hybrid person who\u2019s both a software and data engineer in addition to being a data scientist. The hardcore math people usually fail pretty hard in those environments."
        },
        {
            "id": "hk8nkbn",
            "parent": "t1_hk85wum",
            "ans": "I'd argue that it's more appropriate to derive information theory from probability theory, which is itself is derived from measure theory.",
            "score": 2,
            "que": "That depends. I'd argue data science benefits more from information theory, however, probability can be built using information theory so I guess it's about the same."
        },
        {
            "id": "hk8g1na",
            "parent": "t1_hk8cwly",
            "ans": "Maybe in smaller companies or places where DS is not the main gig. But that has not been the case in my (8 years) experience. Data Scientists in my company are forbidden from doing anything production actually. And for good reasons. To build and maintain a business critical data product you need a specialised workforce, that means Data Scientists who are well versed in the maths/stats side of things, and engineers who are well versed in the software side of things. There are of course people who are very good at both but obviously they are all at Google, Netflix etc.",
            "score": 3,
            "que": "I bet they do but since they know how to use docker, kubernetes, Hadoop, AWS or GCP, they will get the job over someone who just knows stats and none of the other technical skills.\n\n\n-a stats graduate who realized that my undergrad degree is perfect on paper but needs to become a hard core programmer too"
        },
        {
            "id": "hka7bwk",
            "parent": "t1_hk7zbbk",
            "ans": "Which is also kind of BS because real world data is generally not uniformly random. What are the odds your customer was 'born' January 1, 1970? Greater than you'd think.",
            "score": 2,
            "que": "I forget the exact question (which is relevant when doing a riddle) but IIRC the answer was similar in concept to the [birthday paradox](https://en.wikipedia.org/wiki/Birthday_problem) which I would have been glad to talk about if it wasn't obfuscated."
        },
        {
            "id": "hk8bgi7",
            "parent": "t1_hk80s6v",
            "ans": "Nice try buzzfeed writer. Make your own headlines",
            "score": 3,
            "que": "[deleted]"
        },
        {
            "id": "hk84zpn",
            "parent": "t1_hk792b5",
            "ans": "from collections import sort",
            "score": 2,
            "que": "[deleted]"
        },
        {
            "id": "hk854ep",
            "parent": "t1_hk7ecrp",
            "ans": "Cool. You select for people who know how to bullshit their way through interviews, and I'll select for people I want to work with.",
            "score": 3,
            "que": "I think the problem is you still weren't able to demonstrate anything. It's easier to say you could look it up than to do it successfully.\n\nSo, in the scheme of things, your interview will be dinged for that, compared to someone that was able to do it. Both will be miles ahead of someone that tries to confidently BS and gets it wrong."
        },
        {
            "id": "hk7uuxe",
            "parent": "t1_hk7feo2",
            "ans": "That means nothing, collecting them implies greater cost at scale.\n\nForests produce truffles for free, but you won't buy much weight for \u00a31.",
            "score": 1,
            "que": "[deleted]"
        },
        {
            "id": "hkcswl6",
            "parent": "t1_hkaqhp1",
            "ans": "You definitely need to know core concepts. There\u2019s no way adhd is preventing that understanding to the degree you\u2019re presenting.\n\nIf I ask someone what a value is and their response is, \u201cidk because adhd\u201d why would I expect them to remember during work settings?",
            "score": 6,
            "que": "ADHD brains don't work like that tho, we just forget everything all the time. This doesn't actually affect our work because we edit 500x more than the average person, but it seems impossible to convey that concept in the interview without coming off like we're making excuses. \n\nI don't need to remember almost anything to do my job correctly - what matters is the core understanding and the ability to figure stuff out, and both are there. It's just the details that get mixed up in the moment. (For the record I'm more of a programmer than a mathematician but I never struggled with math when given the time I needed).\n\nHonestly looking for suggestions here because I've hit the same issue so many times and I'm at a loss at this point (and have a technical interview coming up as a bonus). Do I tell them I have ADHD? Not sure what else I can do"
        },
        {
            "id": "hkbc5qn",
            "parent": "t1_hkad3fb",
            "ans": "Prove that 1 + 1 = 2.",
            "score": 1,
            "que": "I once saw a PhD defence where a committee member asked the student what a P value meant (after he had reported several). It stumped him.\n\nFoundational questions are wholly appropriate."
        },
        {
            "id": "hkdjrk2",
            "parent": "t1_hkad3fb",
            "ans": "Saw the same situation, this time explain what is the t-statistic that you have used so much in your thesis.",
            "score": 1,
            "que": "I once saw a PhD defence where a committee member asked the student what a P value meant (after he had reported several). It stumped him.\n\nFoundational questions are wholly appropriate."
        },
        {
            "id": "hk977ye",
            "parent": "t1_hk892on",
            "ans": "> How would you define cheating?\n\nIf you could honestly tell how you did it. \u201cCheck Google\u201d -> fine, \u201casked a friend about this obscure detail\u201d -> fine, \u201cgot someone to do the entire thing and I barely know what\u2019s going on\u201d -> not fine",
            "score": 7,
            "que": "How would you define cheating?\n\nBusiness usually cares more about you actually figuring something out, not how you did it.\n\nIf it's a common problem I could see cheating being akin to plagiarism, and you avoid it by baking your own problem rather than using one you found in a blog post or something."
        },
        {
            "id": "hk8jt86",
            "parent": "t1_hk892on",
            "ans": "They get a friend to basically tell them how to do it or do it for them.  This isn't useful if we hire them.  Their friend likely won't have time to do this for everything.",
            "score": 8,
            "que": "How would you define cheating?\n\nBusiness usually cares more about you actually figuring something out, not how you did it.\n\nIf it's a common problem I could see cheating being akin to plagiarism, and you avoid it by baking your own problem rather than using one you found in a blog post or something."
        },
        {
            "id": "hk8zp8b",
            "parent": "t1_hk8ysax",
            "ans": "This is exactly the sort of response I'd want a candidate to be able to provide. Maybe not as well thought out if I'm putting them on the spot but at least something in this vein!\n\nAnd sorry, I think my comment was unclear. I wasn't asking for the answer on what a p-value is, but rather I was asking the other commenter to help me understand how they would not be able to answer this with 8 years experience.",
            "score": 7,
            "que": "Statistician here. A p-value is the probability of getting a result as or more extreme as your data under the conditions of the null hypothesis. Essentially you are saying, \"if the null hypothesis is true and is actually what's going on, how strange is my data?\" If your data is pretty consistent with the situation under the null hypothesis, then you get a larger p-value because that reflects that the probability of your situation occurring is quite high. If your data is not consistent with the situation under the null hypothesis, then you get a smaller p-value because that reflects that the probability of your situation occurring is quite low.\n\nWhat to do with the information you get from your p-value is a whole topic of debate. This is where alpha level, Type I error rate, significance, etc. show up. How do you use your p-value to decide what to do? In most of the non-stats world, you compare it to some significance level and use that to decide whether to accept the null hypothesis or reject it in favor of the alternative hypothesis (which is you saying that you have concluded that the alternative hypothesis is a better explanation for your data than the null hypothesis, not that the alternative hypothesis is correct). The significance level is arbitrary. If you think about setting your significance level to be 0.5, then you reject the null hypothesis when your p-value is 0.49 and accept it when your p-value is 0.51. But that's a very small difference in those p-values. You had to make the cut-off somewhere, so you end up with these types of splits.\n\nKeep in mind that you actually *didn't* have to make the cut-off somewhere. Non-statisticians want a quick and easy way to make a decision so they've gone crazy with significance levels (especially 0.05) but p-values are not decision making tools. They're being used incorrectly.\n\nMost people fundamentally misunderstand what a p-value measures and they thinks it's P(H0|Data) when it's actually P(Data|H0).\n\n(Note that this is the definition of a frequentist p-value and not a Bayesian p-value.)\n\nEdit: sorry, forgot to answer your actual question.\n\n> get a p-value of 0.1\n\nA p-value of 0.1 means that if you ran your experiment perfectly 1000 times and you satisfied all of the conditions of the statistical test perfectly each of the 1000 times then if the null hypothesis is what's really going on, you would get results as strange or stranger than your about 100 every 1000 experiments. Is this situation unusual enough that you end up deciding to reject the null hypothesis in favor of the alternative hypothesis? A lot of people will say that a p-value of 0.1 isn't small enough because getting your results about 10% of the time under the conditions of the null hypothesis isn't enough evidence to reject the null hypothesis as an explanation."
        },
        {
            "id": "hkadv9s",
            "parent": "t1_hk8ysax",
            "ans": "You are responding to a comment that got it right. For a statistician, I would expect your answer, but for a data-whatever job, the post you are responding to would be entirely sufficient.",
            "score": 2,
            "que": "Statistician here. A p-value is the probability of getting a result as or more extreme as your data under the conditions of the null hypothesis. Essentially you are saying, \"if the null hypothesis is true and is actually what's going on, how strange is my data?\" If your data is pretty consistent with the situation under the null hypothesis, then you get a larger p-value because that reflects that the probability of your situation occurring is quite high. If your data is not consistent with the situation under the null hypothesis, then you get a smaller p-value because that reflects that the probability of your situation occurring is quite low.\n\nWhat to do with the information you get from your p-value is a whole topic of debate. This is where alpha level, Type I error rate, significance, etc. show up. How do you use your p-value to decide what to do? In most of the non-stats world, you compare it to some significance level and use that to decide whether to accept the null hypothesis or reject it in favor of the alternative hypothesis (which is you saying that you have concluded that the alternative hypothesis is a better explanation for your data than the null hypothesis, not that the alternative hypothesis is correct). The significance level is arbitrary. If you think about setting your significance level to be 0.5, then you reject the null hypothesis when your p-value is 0.49 and accept it when your p-value is 0.51. But that's a very small difference in those p-values. You had to make the cut-off somewhere, so you end up with these types of splits.\n\nKeep in mind that you actually *didn't* have to make the cut-off somewhere. Non-statisticians want a quick and easy way to make a decision so they've gone crazy with significance levels (especially 0.05) but p-values are not decision making tools. They're being used incorrectly.\n\nMost people fundamentally misunderstand what a p-value measures and they thinks it's P(H0|Data) when it's actually P(Data|H0).\n\n(Note that this is the definition of a frequentist p-value and not a Bayesian p-value.)\n\nEdit: sorry, forgot to answer your actual question.\n\n> get a p-value of 0.1\n\nA p-value of 0.1 means that if you ran your experiment perfectly 1000 times and you satisfied all of the conditions of the statistical test perfectly each of the 1000 times then if the null hypothesis is what's really going on, you would get results as strange or stranger than your about 100 every 1000 experiments. Is this situation unusual enough that you end up deciding to reject the null hypothesis in favor of the alternative hypothesis? A lot of people will say that a p-value of 0.1 isn't small enough because getting your results about 10% of the time under the conditions of the null hypothesis isn't enough evidence to reject the null hypothesis as an explanation."
        },
        {
            "id": "hk8t6hh",
            "parent": "t1_hk8oir1",
            "ans": "this is just wrong from the first sentence onwards\n\n> Now 0.05 < 0.1, thus the causation et al being checked is not significant / most probably occurred by chance.\n\nthis is like instant interview fail territory",
            "score": 3,
            "que": "The p-value is basically the probability of something (event/situation) having occurred by random chance. So basically, higher this value, more is the probability that it occurred just by chance. If you look at the flipside now, the lower this value is, the lower the probability that that event/situation occurred by chance, which means you can say, with certain confidence, that X caused Y if you get my drift.\n\nFor eg: \nYou have yearly Data of sales of a local rainwear store. The store owner tells you that sales increases during the monsoon as opposed to others. This will be your null hypothesis. \n\nThen you set your significance level (this decides whether the p value is significant or not). Most commonly used significance level is 95%. \nI'll use this for this example. \n\nInterpretation:\n\nLets consider that whatever analysis you do gives you a p-value of 0.1. Significance threshold is 100%-95%= 5% or 0.05. Now 0.05 < 0.1, thus the causation et al being checked is not significant / most probably occurred by chance. In plain terms, the monsoon does NOT drive sales at this store. \n\nIf the p value is lower than 0.05 in this example, then it most probably did NOT occur by chance. In plain terms, we can say that sales increases during the monsoon.\n\nTLDR: At a predetermined significance level, we can use the p-value from our analysis to ascertain if the causation we're testing occurred by chance or not depending on whether it's more or less than the p-value  derived from the significance threshold."
        },
        {
            "id": "hk8tq78",
            "parent": "t1_hk8oir1",
            "ans": "Under frequentist assumptions that work really well for ball bearings and beer, but less well in complex human systems. \n\nP-value is an easy question to evaluate because there are very clear ways to calculate and interpret it correctly and very clear ways to calculate and interpret incorrectly. But it's really most useful in highly controlled environments like clinical trials. When I discuss p-values with staff (not in an interview), I'm more interested in what meaning can be attached to their null hypothesis and whether they've really got a dataset that is conducive to only one, actionable alternate hypothesis.\n\nIn uncontrolled, unplanned data collected from a group of humans, almost nothing is truly random. To use an engineering analogy, the problem with human generated data isn't signal-to-noise ratio, it's interference from other signals that you don't happen to be interested in at the moment.",
            "score": 1,
            "que": "The p-value is basically the probability of something (event/situation) having occurred by random chance. So basically, higher this value, more is the probability that it occurred just by chance. If you look at the flipside now, the lower this value is, the lower the probability that that event/situation occurred by chance, which means you can say, with certain confidence, that X caused Y if you get my drift.\n\nFor eg: \nYou have yearly Data of sales of a local rainwear store. The store owner tells you that sales increases during the monsoon as opposed to others. This will be your null hypothesis. \n\nThen you set your significance level (this decides whether the p value is significant or not). Most commonly used significance level is 95%. \nI'll use this for this example. \n\nInterpretation:\n\nLets consider that whatever analysis you do gives you a p-value of 0.1. Significance threshold is 100%-95%= 5% or 0.05. Now 0.05 < 0.1, thus the causation et al being checked is not significant / most probably occurred by chance. In plain terms, the monsoon does NOT drive sales at this store. \n\nIf the p value is lower than 0.05 in this example, then it most probably did NOT occur by chance. In plain terms, we can say that sales increases during the monsoon.\n\nTLDR: At a predetermined significance level, we can use the p-value from our analysis to ascertain if the causation we're testing occurred by chance or not depending on whether it's more or less than the p-value  derived from the significance threshold."
        },
        {
            "id": "hkaupa3",
            "parent": "t1_hk810v8",
            "ans": "I failed a college interview really badly while I was in highschool. I now know I'm pretty good at math, but I really didn't get math until my first semester of college unfortunately, I very much didn't understand the questions they were asking at a conceptual level, despite mechanically being able to do them for the most part. It's ok not to know things - just means you're not done growing yet :)",
            "score": 1,
            "que": "[deleted]"
        },
        {
            "id": "hkatptu",
            "parent": "t1_hkaeiq9",
            "ans": "In most biology we also stick to 0.05. But we *also* tend to require orthogonal approaches to the same question and a handful of other experiments that get at the same idea.\n\nSo, yeah, 0.05 is the threshold, but really it's the congruence of a (often rather large) set of experiments.",
            "score": 1,
            "que": "In empirical research you can't prove anything. You can only gather more evidence. In academia the threshold for \"hmm, you might be onto something, let's print it and see what others think\" is 5% in social sciences and 5 sigma (so waaaay less than 5%) in particle physics with most other science falling somewhere in between.\n\nIt doesn't **mean** anything except that it's an interesting enough of a result to write it down and share it with others.\n\nIt takes a meta-analysis of dozens of experiments and multiple repeated studies in different situations using different methods to actually accept it as a scientific fact. And this does not involve p-values."
        },
        {
            "id": "hkb6zor",
            "parent": "t1_hkarpl5",
            "ans": "I think we have very different definitions of what is a trivia question.",
            "score": 3,
            "que": "It's a trivia question.  Both trivia questions and riddles have been shown in studies to not correlate to employee performance.  Many companies ban them, eg Google used to give these kinds of questions but since has banned them."
        },
        {
            "id": "hk92pra",
            "parent": "t1_hk8xm22",
            "ans": "> no grounding from which to derive a non-arbitrary threshold\n\nThere's lots of ways to derive a non-arbitrary threshold. The obvious one is that you're okay with a 5% chance of making the wrong decision, in which case an alpha level of 5% makes sense. This is not how most people use significance levels and they do just arbitrarily use 5% because that's what they've been told to do, even if it doesn't make sense in their situation. Just because people are using things incorrectly doesn't mean that they're useless.\n\n> p-values are absolutely uninformative\n\nP-values are informative by definition. You are getting information about your data and its probability under the conditions of the null hypothesis. What you choose to do with that information is up to you.\n\n> p-values are not universally applicable\n\nThis doesn't make any sense. P-values are not \"applicable\" to anything.",
            "score": 1,
            "que": "> threshold can be arbitrary\n\nThis is the problem.  If you have no grounding from which to derive a non-arbitrary threshold, then p-values are absolutely uninformative.  Put another way, p-values are not universally applicable."
        },
        {
            "id": "hkatx2x",
            "parent": "t1_hkast7u",
            "ans": "Just the other day we had two new competing brands that can go in our product, promising a lower price, so the company wanted to know which product was the best and by how much.  This involved giving these competing products out to customers in the field.\n\nWhile a p-value could have been used here, and classically would be, management at this particularly company doesn't grok or value p-values so I omitted it from my report.  If the different brands were similar enough I would have had to bring up what an ideal percent of error looks like so just because one looks 1% better doesn't mean it is 1% better, which is basically a p-value in disguise.  Thankfully the difference was drastic so no p-value was necessary.",
            "score": 1,
            "que": "What do you need p-values for?\n\nThis type of experimentation cares about practical significance. P-values are about statistical significance.\n\nYou say \"blindly collecting data\". I am 100% sure you're not talking about experiments. You're talking about optimizing against some type of objective but you don't know much about optimization so you default to stats 101 and think \"experiments, hypothesis, p-value\".\n\nTypical XY problem. You focus on the wrong solution to your actual problem.\n\nI have not encountered a situation outside of academia (social sciences) and clinical trials where you'd need statistical tests and p-values. And even then it's mostly for historical reasons. The journals just require you to do p-values and it's not actually the best approach."
        },
        {
            "id": "hk8656d",
            "parent": "t1_hk808a4",
            "ans": "That's what they do in aggregate though.\n\nThe tech screen / whiteboard interviews are still really common, where you get a barrage of questions from software engineers and mathematicians/statisticians and are expected to know a bunch of random, unpredictable stuff the 4-5 interviewees have used in their career.\n\nOne question failed or not to someone's standards and you're out.\n\nI personally think that interview strategy is rife with survivorship bias. They stumble upon a person that just happened to prep for the random questions they proposed. They're not measuring their ability to think, adapt and learn new things nor their ability to produce good products.\n\nTake-home projects are better IMHO as it's more like real work and actually evaluates more things you want in a good employee, like communication ability, creativity, adaptability, etc.",
            "score": 12,
            "que": "That sounds like companies expecting way too much from people, and is a recipe for failure."
        },
        {
            "id": "hk84bou",
            "parent": "t1_hk808a4",
            "ans": "It can be, but it\u2019s also a great skill set for a smaller group that wants to move quick and build a working product from the ground up.",
            "score": 1,
            "que": "That sounds like companies expecting way too much from people, and is a recipe for failure."
        },
        {
            "id": "hk96zjo",
            "parent": "t1_hk8g1na",
            "ans": "In all the companies that I want to work for, Because they pay all their workers live able wages, great benefits, have done right by their employees even if they didn\u2019t Squeeze out .003% more profit by doing so, they all seem to want to great ETL and other data engineering in addition to classical traditional data science roles",
            "score": 1,
            "que": "Maybe in smaller companies or places where DS is not the main gig. But that has not been the case in my (8 years) experience. Data Scientists in my company are forbidden from doing anything production actually. And for good reasons. To build and maintain a business critical data product you need a specialised workforce, that means Data Scientists who are well versed in the maths/stats side of things, and engineers who are well versed in the software side of things. There are of course people who are very good at both but obviously they are all at Google, Netflix etc."
        },
        {
            "id": "hk8frh1",
            "parent": "t1_hk8bgi7",
            "ans": "Data Scientists hate him!",
            "score": 2,
            "que": "Nice try buzzfeed writer. Make your own headlines"
        },
        {
            "id": "hk865az",
            "parent": "t1_hk854ep",
            "ans": "Saying \"I can't do it now but I can if I google it\" seems more BS to me than being able to work through the problem. \n\nHow is it BS? You worked through the problem or you didn't. However, I can make promises about some future event without anything to back it up, which is the definition of BS, easily. I don't think it should be a negative but I can see where the other user is coming from saying you'll be dinged.",
            "score": -2,
            "que": "Cool. You select for people who know how to bullshit their way through interviews, and I'll select for people I want to work with."
        },
        {
            "id": "hkdj9hz",
            "parent": "t1_hkcswl6",
            "ans": "There's nothing preventing understanding at all - the problem is with recall, which is a far less important skill when your entire job is done on a computer anyway.\n\nI'm a recent graduate with a Bachelor's so maybe it's a question of experience to an extent. I'm not the one deciding which models to use and how to interpret results - I'm just the implementation person for now. I completely agree that I need more math background to be able to make the right decisions. \n\nMy point is just that I always manage to mix up concepts that I do fully understand just because I'm being put on the spot, even if the question is stupid easy. It does not matter at all because I always double check things when I'm working. Googling is just a refresher, not a lesson. I've worked on some really cool projects but none of what I actually can do seems to matter if I make one dumb mistake in the interview.",
            "score": 4,
            "que": "You definitely need to know core concepts. There\u2019s no way adhd is preventing that understanding to the degree you\u2019re presenting.\n\nIf I ask someone what a value is and their response is, \u201cidk because adhd\u201d why would I expect them to remember during work settings?"
        },
        {
            "id": "hlrsg9a",
            "parent": "t1_hkcswl6",
            "ans": "I have the same thing. I forget python syntax all the time for example, but that doesn't mean I don't know how to code. \n\nIf something can be googled very quickly, then there is no reason to test someone on it.\n\nA better way to test ability is to give an example of a concept application, allow the interviewee to be reminded of anything they can't remember by asking you, and then ask the interviewee whether the application makes sense or not.  \n\n\nAsking what a p-value is, is just a lazy and badly designed question.",
            "score": 1,
            "que": "You definitely need to know core concepts. There\u2019s no way adhd is preventing that understanding to the degree you\u2019re presenting.\n\nIf I ask someone what a value is and their response is, \u201cidk because adhd\u201d why would I expect them to remember during work settings?"
        },
        {
            "id": "hkcyrbm",
            "parent": "t1_hkbc5qn",
            "ans": "This would be an entirely reasonable request of a student completing a PhD in pure maths to demonstrate they have a mastery of foundational skills to their training. Just as a student defending research results reported as p-values should be able to give a simple and accurate description of what they mean. So what's your point?",
            "score": 5,
            "que": "Prove that 1 + 1 = 2."
        },
        {
            "id": "hk91tcf",
            "parent": "t1_hk8zp8b",
            "ans": "Oh. I totally thought you were asking what a p-value was. Good thing I'm not interviewing with you for a job. :)\n\nI'm honestly not really sure what to say about the other commenter. A masters in biostats and working 10 years but can't explain what a p-value is? That's something. I'm split half and half between being shocked and being utterly unsurprised because I have met a ridiculously high percentage of \"stats people\" who don't know basic stats.",
            "score": 8,
            "que": "This is exactly the sort of response I'd want a candidate to be able to provide. Maybe not as well thought out if I'm putting them on the spot but at least something in this vein!\n\nAnd sorry, I think my comment was unclear. I wasn't asking for the answer on what a p-value is, but rather I was asking the other commenter to help me understand how they would not be able to answer this with 8 years experience."
        },
        {
            "id": "hkadus7",
            "parent": "t1_hk8zp8b",
            "ans": "Nobody except a professor that has a lecture memorized word-for-word and has those explanations, analogies, arguments etc. roll off their tongue due to muscle memory can give you that answer in an interview setting. It's simply impossible.",
            "score": 3,
            "que": "This is exactly the sort of response I'd want a candidate to be able to provide. Maybe not as well thought out if I'm putting them on the spot but at least something in this vein!\n\nAnd sorry, I think my comment was unclear. I wasn't asking for the answer on what a p-value is, but rather I was asking the other commenter to help me understand how they would not be able to answer this with 8 years experience."
        },
        {
            "id": "hk8tqcx",
            "parent": "t1_hk8t6hh",
            "ans": "Explain. In lay man terms without using any jargon given the scenario I've stated in simplest terms to someone without an inkling about data science.",
            "score": -1,
            "que": "this is just wrong from the first sentence onwards\n\n> Now 0.05 < 0.1, thus the causation et al being checked is not significant / most probably occurred by chance.\n\nthis is like instant interview fail territory"
        },
        {
            "id": "hkavvee",
            "parent": "t1_hkatx2x",
            "ans": "This is my point. You don't need p-values out in the real world. I have never used them and have never encountered a situation where I'd even like to use them.\n\nComparing two products is a lot more complicated because there is not a single metric and some of the metrics can be mutually exclusive. And some of them are not a continuous number but instead a category for example or are binary. Even bringing up statistical significance is silly.",
            "score": 1,
            "que": "Just the other day we had two new competing brands that can go in our product, promising a lower price, so the company wanted to know which product was the best and by how much.  This involved giving these competing products out to customers in the field.\n\nWhile a p-value could have been used here, and classically would be, management at this particularly company doesn't grok or value p-values so I omitted it from my report.  If the different brands were similar enough I would have had to bring up what an ideal percent of error looks like so just because one looks 1% better doesn't mean it is 1% better, which is basically a p-value in disguise.  Thankfully the difference was drastic so no p-value was necessary."
        },
        {
            "id": "hkd7f1w",
            "parent": "t1_hk8656d",
            "ans": "I've certainly got through a few just because I happened to read just the right thing the night before.",
            "score": 1,
            "que": "That's what they do in aggregate though.\n\nThe tech screen / whiteboard interviews are still really common, where you get a barrage of questions from software engineers and mathematicians/statisticians and are expected to know a bunch of random, unpredictable stuff the 4-5 interviewees have used in their career.\n\nOne question failed or not to someone's standards and you're out.\n\nI personally think that interview strategy is rife with survivorship bias. They stumble upon a person that just happened to prep for the random questions they proposed. They're not measuring their ability to think, adapt and learn new things nor their ability to produce good products.\n\nTake-home projects are better IMHO as it's more like real work and actually evaluates more things you want in a good employee, like communication ability, creativity, adaptability, etc."
        },
        {
            "id": "hk869i1",
            "parent": "t1_hk865az",
            "ans": "ok",
            "score": 1,
            "que": "Saying \"I can't do it now but I can if I google it\" seems more BS to me than being able to work through the problem. \n\nHow is it BS? You worked through the problem or you didn't. However, I can make promises about some future event without anything to back it up, which is the definition of BS, easily. I don't think it should be a negative but I can see where the other user is coming from saying you'll be dinged."
        },
        {
            "id": "hlrt5jy",
            "parent": "t1_hkcyrbm",
            "ans": "The problem with that is after a while, things like that become 'muscle memory'. It's the whole use it or lose it. The only thing you really need to remember about p-values is that < x means reject null hypothesis. So then it's not surprising that people forget everything else about it, because when do you ever need to know the rest apart from in a test?  \n\n\nPeople shouldn't be expected to remember everything, especially now google exists.",
            "score": 1,
            "que": "This would be an entirely reasonable request of a student completing a PhD in pure maths to demonstrate they have a mastery of foundational skills to their training. Just as a student defending research results reported as p-values should be able to give a simple and accurate description of what they mean. So what's your point?"
        },
        {
            "id": "hk9fu77",
            "parent": "t1_hk91tcf",
            "ans": "They responded separately - they thought I was setting a mucher higher bar for the exactness of the definition than I really was.",
            "score": 2,
            "que": "Oh. I totally thought you were asking what a p-value was. Good thing I'm not interviewing with you for a job. :)\n\nI'm honestly not really sure what to say about the other commenter. A masters in biostats and working 10 years but can't explain what a p-value is? That's something. I'm split half and half between being shocked and being utterly unsurprised because I have met a ridiculously high percentage of \"stats people\" who don't know basic stats."
        },
        {
            "id": "hkb9fak",
            "parent": "t1_hk91tcf",
            "ans": "I have a PhD in statistics not just a Masters. Genuinely, if you cornered me in the supermarket and asked me what a p-value is I couldn't explain it to you. I don't teach much so I would have trouble finding the words. I haven't had to explain what a P-Value is for years.\n\nI am a statistician, I do not think fast.  Thinking fast is *usually* bad in my job.\n\nOf course, I know what a P-Value is, I just could't put it into words if I hadn't prepared them in advance. Luckily, I have papers and software that show that I have technical knowledge.",
            "score": 1,
            "que": "Oh. I totally thought you were asking what a p-value was. Good thing I'm not interviewing with you for a job. :)\n\nI'm honestly not really sure what to say about the other commenter. A masters in biostats and working 10 years but can't explain what a p-value is? That's something. I'm split half and half between being shocked and being utterly unsurprised because I have met a ridiculously high percentage of \"stats people\" who don't know basic stats."
        },
        {
            "id": "hl9r2fi",
            "parent": "t1_hk91tcf",
            "ans": "Is a data scientist a glorified statistician? I'm not sure all job descriptions for data scientists are consistent with each other. I've done machine learning courses and projects and didn't have to use p value.\n\nWell I guess that it's become the field where all stat and math majors go to, hoping they can use all that statistics and math they learned.",
            "score": 1,
            "que": "Oh. I totally thought you were asking what a p-value was. Good thing I'm not interviewing with you for a job. :)\n\nI'm honestly not really sure what to say about the other commenter. A masters in biostats and working 10 years but can't explain what a p-value is? That's something. I'm split half and half between being shocked and being utterly unsurprised because I have met a ridiculously high percentage of \"stats people\" who don't know basic stats."
        },
        {
            "id": "hkcthcr",
            "parent": "t1_hkadus7",
            "ans": "What? Thousands can. Every data scientist at big tech.",
            "score": 2,
            "que": "Nobody except a professor that has a lecture memorized word-for-word and has those explanations, analogies, arguments etc. roll off their tongue due to muscle memory can give you that answer in an interview setting. It's simply impossible."
        },
        {
            "id": "hkb9p80",
            "parent": "t1_hkadus7",
            "ans": "Exactly",
            "score": 1,
            "que": "Nobody except a professor that has a lecture memorized word-for-word and has those explanations, analogies, arguments etc. roll off their tongue due to muscle memory can give you that answer in an interview setting. It's simply impossible."
        },
        {
            "id": "hk8vx9h",
            "parent": "t1_hk8tqcx",
            "ans": "No, I'm not going to do that.  But your explanation involves (at least) three of the most pervasive misconceptions about what p-values are:\n\n> The p-value is basically the probability of something (event/situation) having occurred by random chance\n\nthis is not what a p-value tries to measure, even in layperson's language\n\n> which means you can say, with certain confidence, that X caused Y if you get my drift\n\nyou absolutely **cannot** conclude this in general\n\n> Now 0.05 < 0.1, thus the causation et al being checked is not significant / most probably occurred by chance\n\nit's absolutely not causation, and (under the null hypothesis and in the absence of degree-of-freedom considerations that tend to lead to unrealistically small p-values in real-world situations) there is still only a 10% chance of observing a result this small.  that is definitely not 'most probably ... by chance'!",
            "score": 3,
            "que": "Explain. In lay man terms without using any jargon given the scenario I've stated in simplest terms to someone without an inkling about data science."
        },
        {
            "id": "hkctwcq",
            "parent": "t1_hk8tqcx",
            "ans": "This sort of confidence despite  being so wrong is particularly pervasive in data science and exactly why these questions are asked.",
            "score": 2,
            "que": "Explain. In lay man terms without using any jargon given the scenario I've stated in simplest terms to someone without an inkling about data science."
        },
        {
            "id": "hk8vryv",
            "parent": "t1_hk8tqcx",
            "ans": "I'm not sure I'd go so far as to say this is completely wrong. But p-value > 0.05 does not mean what you observed most likely happened by chance. At best it is ambiguous. \n\nThe common test criteria of p < 0.05 means you want to have a less than 1/20 chance of mistakenly concluding that what you observed was not random, when it really was. It says nothing about the probability that a truly non-random result will be distinguishable from a random one.\n\nIt also says nothing about what non-randomness actually means in terms of causation or generalizability, and comes with a whole bunch of assumptions that you can directly verify and control in a planned experiment, but not in observational data that you just happen to record.",
            "score": 1,
            "que": "Explain. In lay man terms without using any jargon given the scenario I've stated in simplest terms to someone without an inkling about data science."
        },
        {
            "id": "hkg2zfg",
            "parent": "t1_hkavvee",
            "ans": "Academic here. P-values are used extensively in research, but they could very easily be used when comparing two products if those two products received ratings and those ratings were then compared statistically. That seems far better than just looking at means or just asking folks which they like better (although both would be best).",
            "score": 1,
            "que": "This is my point. You don't need p-values out in the real world. I have never used them and have never encountered a situation where I'd even like to use them.\n\nComparing two products is a lot more complicated because there is not a single metric and some of the metrics can be mutually exclusive. And some of them are not a continuous number but instead a category for example or are binary. Even bringing up statistical significance is silly."
        },
        {
            "id": "hlrx29c",
            "parent": "t1_hlrt5jy",
            "ans": ">The only thing you really need to remember about p-values is that < x means reject null hypothesis.\n\nI completely disagree. If the job is explicitly data science/analysis/statistics/etc, then the person better have an understanding of the nuances of p values and hypothesis testing. I'm not asking for a textbook mathematical proof here, this is a basic question. Without that, they can make rather elementary interpretation mistakes.",
            "score": 1,
            "que": "The problem with that is after a while, things like that become 'muscle memory'. It's the whole use it or lose it. The only thing you really need to remember about p-values is that < x means reject null hypothesis. So then it's not surprising that people forget everything else about it, because when do you ever need to know the rest apart from in a test?  \n\n\nPeople shouldn't be expected to remember everything, especially now google exists."
        },
        {
            "id": "hkd0zk4",
            "parent": "t1_hkb9fak",
            "ans": "That's really interesting. I've found that I have to explain stuff like p-values a lot because I almost always work with non-statisticians and they need to understand the basics. Sounds like we've had very different career experiences.",
            "score": 1,
            "que": "I have a PhD in statistics not just a Masters. Genuinely, if you cornered me in the supermarket and asked me what a p-value is I couldn't explain it to you. I don't teach much so I would have trouble finding the words. I haven't had to explain what a P-Value is for years.\n\nI am a statistician, I do not think fast.  Thinking fast is *usually* bad in my job.\n\nOf course, I know what a P-Value is, I just could't put it into words if I hadn't prepared them in advance. Luckily, I have papers and software that show that I have technical knowledge."
        },
        {
            "id": "hlaen8u",
            "parent": "t1_hl9r2fi",
            "ans": "> Is a data scientist a glorified statistician?\n\nI would say not. Data scientists seem to use a moderate subset of statistics (like the statistical part of machine learning) but they also do a lot of stuff that isn't statistics (like programming) and stuff that technically isn't statistics but is used in statistics commonly (like algorithms). In my opinion, there's a set of things that data scientists use from statistics but which they only have surface level understanding of, although some data scientists I've talked to have educated themselves more because they decided that they needed to.\n\n> I've done machine learning courses and projects and didn't have to use p value.\n\nThat makes sense. P-values are just one aspect of the consideration of how well something works. For a statistical test where you want to judge your individual results in a stochastic environment, they can be useful. In other areas like the evaluation of how well models are working, they may not be useful. P-values are a very small part of the field of statistics.\n\nI was surprised because I thought a previous commenter was saying that he had a masters in biostats and had been working in biostats and he didn't understand what a p-value was. Biostats and data scientist are definitely not the same thing and I would expect a biostatistician to fully understand the idea of a p-value. Turns out he was saying that he doesn't have a good, basic explanation of what a p-value is ready at the tip of his tongue.\n\n>not sure all job descriptions for data scientists are consistent with each other\n\nThere's a lot of issues with definitions of things (which is why I was so vague in the first paragraph). What's the definition of data science? What's the definition of a data scientist? What's the definition of machine learning? Etc. I'm sure that most people in this sub-reddit could agree on the very basic idea of data science - the intersection of parts of programming, math/stats, and algorithms to produce data models that are fitted and updated automatically by computers (although people may already disagree with my attempt at a definition) - but it's still a quite new field and it's got the uncertainty that comes along with still getting itself established in its area.\n\n> Well I guess that it's become the field where all stat and math majors go to, hoping they can use all that statistics and math they learned.\n\nThings would look very, very different if that's what was going on. If you're a stats major, you don't need to go to data science to get a job. In my experience, there's a lot more CS or computer people who have gotten into data science because they either encountered it in a job and found it to be interesting or they ended up in a job where they basically had to invent parts of it outright and then discovered that there is a lot of other people who have had the exact same problems.\n\nI ended up running into a bunch of problems in the area we are now calling \"data science\" back in the very early 2000s because I was working in genetics and we were having serious issues with large data sets. Due to technological advances it had become possible to run GWAS and nobody had the resources to handle the sheer amount of data that was generated, much less to analyze it. These days our \"enormous data sets!!!\" are hilarious (like 600,000+ SNPs across 5,000 or 10,000 samples) but I ended up working out how to do data transfer, storage, and analysis for studies in collaboration with labs at a bunch of academic and medical institutions mostly in the UK and US but also in several European countries because we had no other option.\n\nWhat we now call \"data science\" has been around for a lot longer than people realize. I'm not upset that it has shifted from the group of people who do the analysis (stats) to the group of people who do the computational side (CS). But IMO there is a serious weakness due to lack of understanding of the underlying math/stats that generate the data models. For example, look at the misunderstanding that lots of commenters on this sub have for R, either as a language or as a stats tool.",
            "score": 1,
            "que": "Is a data scientist a glorified statistician? I'm not sure all job descriptions for data scientists are consistent with each other. I've done machine learning courses and projects and didn't have to use p value.\n\nWell I guess that it's become the field where all stat and math majors go to, hoping they can use all that statistics and math they learned."
        },
        {
            "id": "hk95mbv",
            "parent": "t1_hk8vx9h",
            "ans": "Now, from what I think how you've perceived my response, we're looking at this from very different points of view.\n\nP value: For the run of the mill business people, they couldn't care less about the academic definition. In my example, question is do people buy more rainwear during the monsoon or not? Now when I say \"certain confidence\", that does not mean 100% certainty. In layman's terms certain confidence isn't the same as I'm confident for certain.. anyway.. With all due respect, I can absolutely conclude what I did. It might be simplistic and frequentist, but with ONE independent variable, I don't need to worry about any dof. Enough for an interview involving p values. \n\nAs for interpretation, if someone is stupid enough to stay \"this is causation with certainty\", well they deserve the hellfire what follows in case the decision takes because of this study resulted in the company results going south. \n\nWhen I say causation, it's not the statistic causation, it's the assumed \"cause\" given by the store owner in my example. Its not the standard definition, it's what a \"standard layman with no DS knowledge\" would understand.",
            "score": -2,
            "que": "No, I'm not going to do that.  But your explanation involves (at least) three of the most pervasive misconceptions about what p-values are:\n\n> The p-value is basically the probability of something (event/situation) having occurred by random chance\n\nthis is not what a p-value tries to measure, even in layperson's language\n\n> which means you can say, with certain confidence, that X caused Y if you get my drift\n\nyou absolutely **cannot** conclude this in general\n\n> Now 0.05 < 0.1, thus the causation et al being checked is not significant / most probably occurred by chance\n\nit's absolutely not causation, and (under the null hypothesis and in the absence of degree-of-freedom considerations that tend to lead to unrealistically small p-values in real-world situations) there is still only a 10% chance of observing a result this small.  that is definitely not 'most probably ... by chance'!"
        },
        {
            "id": "hkg6cbf",
            "parent": "t1_hkg2zfg",
            "ans": "What kind of a business has 2 products that they compare once and that's it? Sure it's the situation in academia because then the research is over and you write a paper.\n\nOut in the real world things are different. You never really care if there is a statistically significant difference between 2 products. You care about picking the best one. Optimizing for the best option isn't really solvable with p-values. This is a textbook optimization problem, not a hypothesis testing problem.\n\nThis is precisely my point. People with \"statistics for social science\" or an undergrad in stats think that stuff they learned that was specifically tailored for academic research (or clinical research) is directly applicable out in the real world.\n\nWhen all you have is a hammer, everything starts to look like a nail. In real world data science statistics are basically irrelevant.",
            "score": 1,
            "que": "Academic here. P-values are used extensively in research, but they could very easily be used when comparing two products if those two products received ratings and those ratings were then compared statistically. That seems far better than just looking at means or just asking folks which they like better (although both would be best)."
        },
        {
            "id": "hls34l5",
            "parent": "t1_hlrx29c",
            "ans": "I get that, but at the same time you can make interpretation mistakes in any number of ways. You aren't really plugging any leaks by asking such questions. Questions like this also encourage interviewees to treat interviews like school exams, where memorization becomes more important than understanding.",
            "score": 1,
            "que": ">The only thing you really need to remember about p-values is that < x means reject null hypothesis.\n\nI completely disagree. If the job is explicitly data science/analysis/statistics/etc, then the person better have an understanding of the nuances of p values and hypothesis testing. I'm not asking for a textbook mathematical proof here, this is a basic question. Without that, they can make rather elementary interpretation mistakes."
        },
        {
            "id": "hk9eujf",
            "parent": "t1_hk95mbv",
            "ans": "> With all due respect, I can absolutely conclude what I did. It might be simplistic and frequentist, but with ONE independent variable, I don't need to worry about any dof. \n\nso, if you believe that the setup is fine in this comparison, and (from the stated p-value) there's only a 10% chance of observing a result this extreme by random chance, why is your conclusion that that the causation \"most probably occurred by chance\"?\n\nyour answers aren't even internally consistent",
            "score": 1,
            "que": "Now, from what I think how you've perceived my response, we're looking at this from very different points of view.\n\nP value: For the run of the mill business people, they couldn't care less about the academic definition. In my example, question is do people buy more rainwear during the monsoon or not? Now when I say \"certain confidence\", that does not mean 100% certainty. In layman's terms certain confidence isn't the same as I'm confident for certain.. anyway.. With all due respect, I can absolutely conclude what I did. It might be simplistic and frequentist, but with ONE independent variable, I don't need to worry about any dof. Enough for an interview involving p values. \n\nAs for interpretation, if someone is stupid enough to stay \"this is causation with certainty\", well they deserve the hellfire what follows in case the decision takes because of this study resulted in the company results going south. \n\nWhen I say causation, it's not the statistic causation, it's the assumed \"cause\" given by the store owner in my example. Its not the standard definition, it's what a \"standard layman with no DS knowledge\" would understand."
        },
        {
            "id": "hk9oy0g",
            "parent": "t1_hk95mbv",
            "ans": "> P value: For the run of the mill business people, they couldn't care less about the academic definition.\n\nDo they care about logic?\n\n\"It's very unlikely that a US-born citizen is a US senator. Therefore it's very unlikely that a US senator is a US-born citizen.\"\n\nThis is wrong for the same reason that the p-value of something is not the probability that it occurred by chance ([inverse conditional probabilities are not interchangeable](https://en.wikipedia.org/wiki/Conditional_probability#Assuming_conditional_probability_is_of_similar_size_to_its_inverse)). It's not a laymen's understanding, it's just a misunderstanding.\n\nFor any particular p-value, the \"probability it occurred by chance\" can be anything from 0 to 100%. (That's assuming you're comfortable switching probability interpretations. If you stick with the frequentist one p-values are from, then it's either 0 or 100% and *nothing* in between is coherent.)",
            "score": 1,
            "que": "Now, from what I think how you've perceived my response, we're looking at this from very different points of view.\n\nP value: For the run of the mill business people, they couldn't care less about the academic definition. In my example, question is do people buy more rainwear during the monsoon or not? Now when I say \"certain confidence\", that does not mean 100% certainty. In layman's terms certain confidence isn't the same as I'm confident for certain.. anyway.. With all due respect, I can absolutely conclude what I did. It might be simplistic and frequentist, but with ONE independent variable, I don't need to worry about any dof. Enough for an interview involving p values. \n\nAs for interpretation, if someone is stupid enough to stay \"this is causation with certainty\", well they deserve the hellfire what follows in case the decision takes because of this study resulted in the company results going south. \n\nWhen I say causation, it's not the statistic causation, it's the assumed \"cause\" given by the store owner in my example. Its not the standard definition, it's what a \"standard layman with no DS knowledge\" would understand."
        },
        {
            "id": "hkgkm7v",
            "parent": "t1_hkg6cbf",
            "ans": "Some fair points, but some not so fair. Comparing two means is a simple t-test. There are more advanced statistics to answer more complex questions at our disposal. Also medical research comparing drug efficacy relies heavily on statistics, which is a very real-world problem.\n\nWhatever method you use to determine the \"best\" product will rely on some form of data science, whether there is a p-value involved or not.\n\nAnd I'm not an undergrad just FYI!",
            "score": 1,
            "que": "What kind of a business has 2 products that they compare once and that's it? Sure it's the situation in academia because then the research is over and you write a paper.\n\nOut in the real world things are different. You never really care if there is a statistically significant difference between 2 products. You care about picking the best one. Optimizing for the best option isn't really solvable with p-values. This is a textbook optimization problem, not a hypothesis testing problem.\n\nThis is precisely my point. People with \"statistics for social science\" or an undergrad in stats think that stuff they learned that was specifically tailored for academic research (or clinical research) is directly applicable out in the real world.\n\nWhen all you have is a hammer, everything starts to look like a nail. In real world data science statistics are basically irrelevant."
        },
        {
            "id": "hk9h2tg",
            "parent": "t1_hk9eujf",
            "ans": "What are you even saying? \n\nThe 0.1 p value is what I've assumed you get in your analysis. In my example, at 95% confidence, the p value obtained via the analysis is 0.1, which will be greater than the threshold confidence p value, which is 0.05, which means the result is not significant, and is therefore leading to us, in statistical language, reject the null hypothesis. Now this means ambiguity, but how will you explain this to a non DS manager taking the interview? Do they understand what ambiguity means statistically, and even if they do, do they care? In most cases, in my experience, they don't; they want a clear yes or no, which cannot be given in statistical terms. To a non DS interviewer, this makes most sense where they can say it probably is the cause.\n\nDon't get me wrong, I'm not afraid of being wrong. Now if you were me, please explain how you would explain this to an absolute noob of an interviewer, who would reject you at a single mention of jargon, how the scenario what I've mentioned with a single independent variable would play out. I would be absolutely willing to learn if you could elaborate rather than just just dismissal, which amounts to nothing since I don't care about downvotes.\n\nEdit is to correct grammar. English doesn't come naturally to me, apologies.",
            "score": 1,
            "que": "> With all due respect, I can absolutely conclude what I did. It might be simplistic and frequentist, but with ONE independent variable, I don't need to worry about any dof. \n\nso, if you believe that the setup is fine in this comparison, and (from the stated p-value) there's only a 10% chance of observing a result this extreme by random chance, why is your conclusion that that the causation \"most probably occurred by chance\"?\n\nyour answers aren't even internally consistent"
        },
        {
            "id": "hk9s9k4",
            "parent": "t1_hk9oy0g",
            "ans": "It cannot be 100%. Nothing in real world stats can be 100%. That's what the confidence interval is for. What level of error is for is to see if you are comfortable with that particular error percentage along both tails (I'm thinking about LR on a bell curve here). My answer isn't meant to be the be all and end all of stats. It is meant to be that in the given situation that I mentioned, if it were to be applied, would make sense to the non tech person who is selling the concept to a probable client.\n\nNow, just because ALL of my YouTube recommendations  are TRASH (I'm digressing as you are), doesn't mean their algorithm is trash (it is actually). \n\nClients don't care about logic. I've seen that in 5 clients that I've done projects for. Now, they care about sales, they don't care about the means, stats or otherwise. Now without anecdotal evidence, let me pose the question I posed in the beginning since all of you seem to be giving me flak for God knows what reason:\n\nI have monsoon data. Just whether there was rain that day or not, broken down daily. Nothing else. Now I have sales data, also broken down daily. Pretend I'm the non DS interviewer: I want to know if sales are greater during the monsoon or not. I will NOT give you anything else, how would you solve it?\n\nPoint I'm making is, if your point that data may not suffice is shot down, you make do with what you have. Now the point in the comment above mine had nothing to do with concepts, it had to do with how will you explain. That's all it is. Now if a US born citizen is being shown in the data PROVIDED to me that they're unlikely to be a senator, so be it.",
            "score": 0,
            "que": "> P value: For the run of the mill business people, they couldn't care less about the academic definition.\n\nDo they care about logic?\n\n\"It's very unlikely that a US-born citizen is a US senator. Therefore it's very unlikely that a US senator is a US-born citizen.\"\n\nThis is wrong for the same reason that the p-value of something is not the probability that it occurred by chance ([inverse conditional probabilities are not interchangeable](https://en.wikipedia.org/wiki/Conditional_probability#Assuming_conditional_probability_is_of_similar_size_to_its_inverse)). It's not a laymen's understanding, it's just a misunderstanding.\n\nFor any particular p-value, the \"probability it occurred by chance\" can be anything from 0 to 100%. (That's assuming you're comfortable switching probability interpretations. If you stick with the frequentist one p-values are from, then it's either 0 or 100% and *nothing* in between is coherent.)"
        },
        {
            "id": "hkgo3w2",
            "parent": "t1_hkgkm7v",
            "ans": "Comparing 2 things is not the problem you're trying to solve. In academia (and clinical research) you want to publish a research paper and that's why you need a hypothesis and to test it.\n\nThis is not something you want to do in the real world. Even in medical companies the only reason they do statistical tests is because the regulation requires it. Internally they are using optimization techniques.\n\nIf you think \"I should use statistical significance tests\" outside of academia/clinical trials then you're doing it wrong. Mostly likely because you don't know any better.",
            "score": 1,
            "que": "Some fair points, but some not so fair. Comparing two means is a simple t-test. There are more advanced statistics to answer more complex questions at our disposal. Also medical research comparing drug efficacy relies heavily on statistics, which is a very real-world problem.\n\nWhatever method you use to determine the \"best\" product will rely on some form of data science, whether there is a p-value involved or not.\n\nAnd I'm not an undergrad just FYI!"
        },
        {
            "id": "hk9whyt",
            "parent": "t1_hk9s9k4",
            "ans": "Not sure what you mean confidence intervals are for. They're just the collection of values for null hypotheses that you'd fail to reject.\n\nI don't think the 100% (defined as [\"almost surely\"](https://en.wikipedia.org/wiki/Almost_surely), if it's of any consolation) is the detail to get caught on. I don't doubt that a non-tech person understands \"there's a 10% chance this occurred by chance alone.\" But when you tell them that based on p=0.10, the actual chance could .5% or 75% or anything. The p-value doesn't tell you what it is. Because the \"academic\" definition is actually substantially different.\n\n> Now if a US born citizen is being shown in the date PROVIDED to me that they're unlikely to be a senator, so be it.\n\nI meant it in the sense that a US born citizen IS very unlikely to be a senator. There are hundreds of millions of US born citizens and only 95 of them are US senators. (And presumably you agree that it's not 1-in-millions chance that a US senator is US born.)\n\nAlternative content: \"It's very unlikely that an uninfected person tests positive for this disease. Therefore it's very unlikely that a person who tested positive is uninfected.\"",
            "score": 2,
            "que": "It cannot be 100%. Nothing in real world stats can be 100%. That's what the confidence interval is for. What level of error is for is to see if you are comfortable with that particular error percentage along both tails (I'm thinking about LR on a bell curve here). My answer isn't meant to be the be all and end all of stats. It is meant to be that in the given situation that I mentioned, if it were to be applied, would make sense to the non tech person who is selling the concept to a probable client.\n\nNow, just because ALL of my YouTube recommendations  are TRASH (I'm digressing as you are), doesn't mean their algorithm is trash (it is actually). \n\nClients don't care about logic. I've seen that in 5 clients that I've done projects for. Now, they care about sales, they don't care about the means, stats or otherwise. Now without anecdotal evidence, let me pose the question I posed in the beginning since all of you seem to be giving me flak for God knows what reason:\n\nI have monsoon data. Just whether there was rain that day or not, broken down daily. Nothing else. Now I have sales data, also broken down daily. Pretend I'm the non DS interviewer: I want to know if sales are greater during the monsoon or not. I will NOT give you anything else, how would you solve it?\n\nPoint I'm making is, if your point that data may not suffice is shot down, you make do with what you have. Now the point in the comment above mine had nothing to do with concepts, it had to do with how will you explain. That's all it is. Now if a US born citizen is being shown in the data PROVIDED to me that they're unlikely to be a senator, so be it."
        },
        {
            "id": "hkgr70b",
            "parent": "t1_hkgo3w2",
            "ans": "False. A company comparing a new formula to an old formula might conduct survey research to compare public opinions on the change. \n\nClinical trials 100% use statistics and p-values to compare efficacy of drugs. It's not the ONLY thing they use, but statistical signigicance is very real. \n\nI am not sure why you are making such blanket statements about how statistics is used outside academia. Try getting government funding and telling them you will not use any statistics in your research lol.",
            "score": 1,
            "que": "Comparing 2 things is not the problem you're trying to solve. In academia (and clinical research) you want to publish a research paper and that's why you need a hypothesis and to test it.\n\nThis is not something you want to do in the real world. Even in medical companies the only reason they do statistical tests is because the regulation requires it. Internally they are using optimization techniques.\n\nIf you think \"I should use statistical significance tests\" outside of academia/clinical trials then you're doing it wrong. Mostly likely because you don't know any better."
        },
        {
            "id": "hk9wjj0",
            "parent": "t1_hk9whyt",
            "ans": "**[Almost surely](https://en.wikipedia.org/wiki/Almost_surely)** \n \n >In probability theory, an event is said to happen almost surely (sometimes abbreviated as a. s. ) if it happens with probability 1 (or Lebesgue measure 1). In other words, the set of possible exceptions may be non-empty, but it has probability 0.\n \n^([ )[^(F.A.Q)](https://www.reddit.com/r/WikiSummarizer/wiki/index#wiki_f.a.q)^( | )[^(Opt Out)](https://reddit.com/message/compose?to=WikiSummarizerBot&message=OptOut&subject=OptOut)^( | )[^(Opt Out Of Subreddit)](https://np.reddit.com/r/datascience/about/banned)^( | )[^(GitHub)](https://github.com/Sujal-7/WikiSummarizerBot)^( ] Downvote to remove | v1.5)",
            "score": 1,
            "que": "Not sure what you mean confidence intervals are for. They're just the collection of values for null hypotheses that you'd fail to reject.\n\nI don't think the 100% (defined as [\"almost surely\"](https://en.wikipedia.org/wiki/Almost_surely), if it's of any consolation) is the detail to get caught on. I don't doubt that a non-tech person understands \"there's a 10% chance this occurred by chance alone.\" But when you tell them that based on p=0.10, the actual chance could .5% or 75% or anything. The p-value doesn't tell you what it is. Because the \"academic\" definition is actually substantially different.\n\n> Now if a US born citizen is being shown in the date PROVIDED to me that they're unlikely to be a senator, so be it.\n\nI meant it in the sense that a US born citizen IS very unlikely to be a senator. There are hundreds of millions of US born citizens and only 95 of them are US senators. (And presumably you agree that it's not 1-in-millions chance that a US senator is US born.)\n\nAlternative content: \"It's very unlikely that an uninfected person tests positive for this disease. Therefore it's very unlikely that a person who tested positive is uninfected.\""
        },
        {
            "id": "hk9zh81",
            "parent": "t1_hk9whyt",
            "ans": "Again, answer the question what I've asked. I actually don't care much about contexts. Please make sure to give your assumptions and details. I know it can be anything, but when on an interview call in a covid world, what would be your reply based on the scenario that I've asked?\n\nOk to make it easy, let's say that after you analyzed this \"data\", you've got a p value of 0.051. Now, what would be your inference?",
            "score": 1,
            "que": "Not sure what you mean confidence intervals are for. They're just the collection of values for null hypotheses that you'd fail to reject.\n\nI don't think the 100% (defined as [\"almost surely\"](https://en.wikipedia.org/wiki/Almost_surely), if it's of any consolation) is the detail to get caught on. I don't doubt that a non-tech person understands \"there's a 10% chance this occurred by chance alone.\" But when you tell them that based on p=0.10, the actual chance could .5% or 75% or anything. The p-value doesn't tell you what it is. Because the \"academic\" definition is actually substantially different.\n\n> Now if a US born citizen is being shown in the date PROVIDED to me that they're unlikely to be a senator, so be it.\n\nI meant it in the sense that a US born citizen IS very unlikely to be a senator. There are hundreds of millions of US born citizens and only 95 of them are US senators. (And presumably you agree that it's not 1-in-millions chance that a US senator is US born.)\n\nAlternative content: \"It's very unlikely that an uninfected person tests positive for this disease. Therefore it's very unlikely that a person who tested positive is uninfected.\""
        },
        {
            "id": "hkh0rrk",
            "parent": "t1_hkgr70b",
            "ans": "You are describing confirmatory statistics. This is basically exclusive to academia and places where you're legally required to do so (ie. drug trials for the FDA).\n\nNo company will ever set out to \"compare a new formula to an old formula\". That's not how the real world works. The real world has business objectives such as \"make shit cheaper\" or \"bring in more money\". Hypothesis testing is never not a good answer to these business objectives.\n\nYou are a perfect example of someone with no experience dealing with data in the real world so you're stuck in your stats 101 mode.\n\nI've worked at big pharma companies and we did not use hypothesis testing when developing new drugs. We used predictive models and simulations to actually develop the drugs. The clinical trial part was right at the very end and the only reason we did it because regulations demanded it. If the product was not medical (for example an ointment you'd get at a supermarket) we never did any hypothesis testing.\n\nWhy on earth would anyone do hypothesis testing and stare at p-values if they're not trying to get a paper published in a journal that requires them?",
            "score": 1,
            "que": "False. A company comparing a new formula to an old formula might conduct survey research to compare public opinions on the change. \n\nClinical trials 100% use statistics and p-values to compare efficacy of drugs. It's not the ONLY thing they use, but statistical signigicance is very real. \n\nI am not sure why you are making such blanket statements about how statistics is used outside academia. Try getting government funding and telling them you will not use any statistics in your research lol."
        },
        {
            "id": "hka0rgi",
            "parent": "t1_hk9zh81",
            "ans": "Easier to say what I wouldn't say, which is that there's a 5.1% chance that the result occurred by chance alone. And if you still don't get why, then it'd help to know how my other explanations are falling short for you.",
            "score": 1,
            "que": "Again, answer the question what I've asked. I actually don't care much about contexts. Please make sure to give your assumptions and details. I know it can be anything, but when on an interview call in a covid world, what would be your reply based on the scenario that I've asked?\n\nOk to make it easy, let's say that after you analyzed this \"data\", you've got a p value of 0.051. Now, what would be your inference?"
        },
        {
            "id": "hkh3m6i",
            "parent": "t1_hkh0rrk",
            "ans": "You seem to hate p-values for whatever reason and seem to think they are limited to undergraduate research papers. Dont know why you have this idiotic view based on your limited experience but perhaps you should realize that your experience is an N of 1.",
            "score": 1,
            "que": "You are describing confirmatory statistics. This is basically exclusive to academia and places where you're legally required to do so (ie. drug trials for the FDA).\n\nNo company will ever set out to \"compare a new formula to an old formula\". That's not how the real world works. The real world has business objectives such as \"make shit cheaper\" or \"bring in more money\". Hypothesis testing is never not a good answer to these business objectives.\n\nYou are a perfect example of someone with no experience dealing with data in the real world so you're stuck in your stats 101 mode.\n\nI've worked at big pharma companies and we did not use hypothesis testing when developing new drugs. We used predictive models and simulations to actually develop the drugs. The clinical trial part was right at the very end and the only reason we did it because regulations demanded it. If the product was not medical (for example an ointment you'd get at a supermarket) we never did any hypothesis testing.\n\nWhy on earth would anyone do hypothesis testing and stare at p-values if they're not trying to get a paper published in a journal that requires them?"
        },
        {
            "id": "hka2cbp",
            "parent": "t1_hka0rgi",
            "ans": "Forget what I'm asking. You have a client asking. Now 5.1% chance of what occurring? Sales increasing during monsoon? \n\nSee this is not what is correct. This is what a hypothetical person who knows nothing about ds... how would he/she interpret what the 5.1%?\n\nEdit: I think I got you now. See, now, the probability of that occurrence is 5.1%. So since it falls in the \"usual\" part of the bell curve (if we assume LR), means that given our confidence interval, which is 0.05 on each side, and therefore the condition is insignificant. So based on what they have provided (the data I mean), the occurrence is likely to have been random given normal distribution (given LR's assumptions). Hence in this context, the condition, whatever we've assumed in the null hypothesis, cannot be rejected and thus we can say that THAT particular condition doesn't have any bearing. \n\nWhile your second comment seems true, thing is that there is a possibility of that being a factor wherein if increased, can have a greater bearing on the result desired. But this has to be investigated/tested.",
            "score": 1,
            "que": "Easier to say what I wouldn't say, which is that there's a 5.1% chance that the result occurred by chance alone. And if you still don't get why, then it'd help to know how my other explanations are falling short for you."
        },
        {
            "id": "hka347j",
            "parent": "t1_hka2cbp",
            "ans": "A 5.1% chance of seeing sales increase at least that much during monsoons if monsoons don't actually affect sales.",
            "score": 1,
            "que": "Forget what I'm asking. You have a client asking. Now 5.1% chance of what occurring? Sales increasing during monsoon? \n\nSee this is not what is correct. This is what a hypothetical person who knows nothing about ds... how would he/she interpret what the 5.1%?\n\nEdit: I think I got you now. See, now, the probability of that occurrence is 5.1%. So since it falls in the \"usual\" part of the bell curve (if we assume LR), means that given our confidence interval, which is 0.05 on each side, and therefore the condition is insignificant. So based on what they have provided (the data I mean), the occurrence is likely to have been random given normal distribution (given LR's assumptions). Hence in this context, the condition, whatever we've assumed in the null hypothesis, cannot be rejected and thus we can say that THAT particular condition doesn't have any bearing. \n\nWhile your second comment seems true, thing is that there is a possibility of that being a factor wherein if increased, can have a greater bearing on the result desired. But this has to be investigated/tested."
        },
        {
            "id": "hkddcnx",
            "parent": "t1_hka2cbp",
            "ans": "I'm not sure I'm understanding your edit correctly, but it sounds wrong in the same way as other comments you've made.\n\n> So based on what they have provided (the data I mean), the occurrence is likely to have been random given normal distribution (given LR's assumptions).\n\nA p-value is the probability of the occurrence being as extreme as it is *assuming* that it was random. Not the probability that the occurrence was random given how extreme it was.",
            "score": 1,
            "que": "Forget what I'm asking. You have a client asking. Now 5.1% chance of what occurring? Sales increasing during monsoon? \n\nSee this is not what is correct. This is what a hypothetical person who knows nothing about ds... how would he/she interpret what the 5.1%?\n\nEdit: I think I got you now. See, now, the probability of that occurrence is 5.1%. So since it falls in the \"usual\" part of the bell curve (if we assume LR), means that given our confidence interval, which is 0.05 on each side, and therefore the condition is insignificant. So based on what they have provided (the data I mean), the occurrence is likely to have been random given normal distribution (given LR's assumptions). Hence in this context, the condition, whatever we've assumed in the null hypothesis, cannot be rejected and thus we can say that THAT particular condition doesn't have any bearing. \n\nWhile your second comment seems true, thing is that there is a possibility of that being a factor wherein if increased, can have a greater bearing on the result desired. But this has to be investigated/tested."
        },
        {
            "id": "hka43ap",
            "parent": "t1_hka347j",
            "ans": "Erm.... I dont think thats what it means. That percentage is a chance/probability factor, not of the absolute number, feel free to correct me if I'm wrong. Anyway I'm off to sleep, will continue this in the morning :) Thanks for the debate, I really appreciate it.",
            "score": 1,
            "que": "A 5.1% chance of seeing sales increase at least that much during monsoons if monsoons don't actually affect sales."
        },
        {
            "id": "hkarzsp",
            "parent": "t1_hka43ap",
            "ans": "That is a probability. The probability of such a result (one at least as extreme) if the null hypothesis is true.",
            "score": 1,
            "que": "Erm.... I dont think thats what it means. That percentage is a chance/probability factor, not of the absolute number, feel free to correct me if I'm wrong. Anyway I'm off to sleep, will continue this in the morning :) Thanks for the debate, I really appreciate it."
        }
    ]
}